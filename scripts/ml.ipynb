{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from pycaret.classification import ClassificationExperiment\n",
    "from datetime import datetime\n",
    "import patsy\n",
    "import logging\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>HID</th>\n",
       "      <th>AID</th>\n",
       "      <th>N</th>\n",
       "      <th>POFF</th>\n",
       "      <th>Open</th>\n",
       "      <th>OddsH</th>\n",
       "      <th>OddsA</th>\n",
       "      <th>H</th>\n",
       "      <th>A</th>\n",
       "      <th>HSC</th>\n",
       "      <th>ASC</th>\n",
       "      <th>HFGM</th>\n",
       "      <th>AFGM</th>\n",
       "      <th>HFGA</th>\n",
       "      <th>AFGA</th>\n",
       "      <th>HFG3M</th>\n",
       "      <th>AFG3M</th>\n",
       "      <th>HFG3A</th>\n",
       "      <th>AFG3A</th>\n",
       "      <th>HFTM</th>\n",
       "      <th>AFTM</th>\n",
       "      <th>HFTA</th>\n",
       "      <th>AFTA</th>\n",
       "      <th>HORB</th>\n",
       "      <th>AORB</th>\n",
       "      <th>HDRB</th>\n",
       "      <th>ADRB</th>\n",
       "      <th>HRB</th>\n",
       "      <th>ARB</th>\n",
       "      <th>HAST</th>\n",
       "      <th>AAST</th>\n",
       "      <th>HSTL</th>\n",
       "      <th>ASTL</th>\n",
       "      <th>HBLK</th>\n",
       "      <th>ABLK</th>\n",
       "      <th>HTOV</th>\n",
       "      <th>ATOV</th>\n",
       "      <th>HPF</th>\n",
       "      <th>APF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23739</th>\n",
       "      <td>21</td>\n",
       "      <td>1995-11-07</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995-11-06</td>\n",
       "      <td>1.274083</td>\n",
       "      <td>3.794318</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>108</td>\n",
       "      <td>25.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23740</th>\n",
       "      <td>21</td>\n",
       "      <td>1995-11-07</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995-11-06</td>\n",
       "      <td>1.597972</td>\n",
       "      <td>2.286949</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>106</td>\n",
       "      <td>46.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23741</th>\n",
       "      <td>21</td>\n",
       "      <td>1995-11-08</td>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995-11-07</td>\n",
       "      <td>1.471072</td>\n",
       "      <td>2.640288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>91</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23742</th>\n",
       "      <td>21</td>\n",
       "      <td>1995-11-08</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995-11-07</td>\n",
       "      <td>1.257454</td>\n",
       "      <td>3.967424</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>105</td>\n",
       "      <td>31.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23743</th>\n",
       "      <td>21</td>\n",
       "      <td>1995-11-08</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995-11-07</td>\n",
       "      <td>1.302199</td>\n",
       "      <td>3.542703</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>75</td>\n",
       "      <td>31.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Season       Date  HID  AID  N  POFF       Open     OddsH     OddsA  H  \\\n",
       "23739      21 1995-11-07    0   11  0     0 1995-11-06  1.274083  3.794318  0   \n",
       "23740      21 1995-11-07   17   43  0     0 1995-11-06  1.597972  2.286949  1   \n",
       "23741      21 1995-11-08   41   39  0     0 1995-11-07  1.471072  2.640288  0   \n",
       "23742      21 1995-11-08   15   22  0     0 1995-11-07  1.257454  3.967424  0   \n",
       "23743      21 1995-11-08   13   19  0     0 1995-11-07  1.302199  3.542703  1   \n",
       "\n",
       "       A  HSC  ASC  HFGM  AFGM  HFGA  AFGA  HFG3M  AFG3M  HFG3A  AFG3A  HFTM  \\\n",
       "23739  1   66  108  25.0  39.0  65.0  79.0    3.0    7.0   17.0   13.0  13.0   \n",
       "23740  0  114  106  46.0  40.0  83.0  77.0    6.0   13.0   12.0   30.0  16.0   \n",
       "23741  1   87   91  30.0  36.0  75.0  84.0    3.0    1.0   16.0   11.0  24.0   \n",
       "23742  1   97  105  31.0  43.0  72.0  93.0    8.0    2.0   21.0   14.0  27.0   \n",
       "23743  0   88   75  31.0  26.0  74.0  78.0    3.0    4.0    9.0   17.0  23.0   \n",
       "\n",
       "       AFTM  HFTA  AFTA  HORB  AORB  HDRB  ADRB   HRB   ARB  HAST  AAST  HSTL  \\\n",
       "23739  23.0  22.0  32.0   4.0  13.0  25.0  36.0  29.0  49.0  13.0  22.0   6.0   \n",
       "23740  13.0  24.0  17.0  12.0   4.0  31.0  25.0  43.0  29.0  30.0  29.0  11.0   \n",
       "23741  18.0  39.0  33.0  10.0  10.0  42.0  36.0  52.0  46.0  18.0  17.0   5.0   \n",
       "23742  17.0  34.0  25.0  13.0  11.0  35.0  27.0  48.0  38.0  19.0  26.0   3.0   \n",
       "23743  19.0  25.0  22.0  15.0  17.0  32.0  25.0  47.0  42.0  19.0  11.0  10.0   \n",
       "\n",
       "       ASTL  HBLK  ABLK  HTOV  ATOV   HPF   APF  \n",
       "23739  10.0   3.0   5.0  23.0  16.0  24.0  21.0  \n",
       "23740   7.0   1.0   5.0  21.0  21.0  19.0  25.0  \n",
       "23741   6.0   6.0   4.0  19.0  15.0  31.0  31.0  \n",
       "23742  12.0   9.0   0.0  22.0   8.0  23.0  25.0  \n",
       "23743   9.0   6.0   4.0  17.0  18.0  22.0  24.0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(\"..\", \"data\", \"games.csv\")\n",
    "df = pd.read_csv(data_path, parse_dates=[\"Date\", \"Open\"], date_format=\"%Y-%m-%d\", index_col=0)\n",
    "df = df[df[\"Season\"] > 20]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsH = [\"HSC\", \"HFGM\", \"HFGA\", \"HFG3M\", \"HFG3A\", \"HFTM\", \"HFTA\", \"HORB\", \"HDRB\", \"HRB\", \"HAST\", \"HSTL\", \"HBLK\", \"HTOV\", \"HPF\"]\n",
    "columnsA = [\"ASC\", \"AFGM\", \"AFGA\", \"AFG3M\", \"AFG3A\", \"AFTM\", \"AFTA\", \"AORB\", \"ADRB\", \"ARB\", \"AAST\", \"ASTL\", \"ABLK\", \"ATOV\", \"APF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>HID</th>\n",
       "      <th>AID</th>\n",
       "      <th>N</th>\n",
       "      <th>POFF</th>\n",
       "      <th>Open</th>\n",
       "      <th>OddsH</th>\n",
       "      <th>OddsA</th>\n",
       "      <th>H</th>\n",
       "      <th>A</th>\n",
       "      <th>SortedTID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23739</th>\n",
       "      <td>21</td>\n",
       "      <td>1995-11-07</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995-11-06</td>\n",
       "      <td>1.274083</td>\n",
       "      <td>3.794318</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23740</th>\n",
       "      <td>21</td>\n",
       "      <td>1995-11-07</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995-11-06</td>\n",
       "      <td>1.597972</td>\n",
       "      <td>2.286949</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(17, 43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23741</th>\n",
       "      <td>21</td>\n",
       "      <td>1995-11-08</td>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995-11-07</td>\n",
       "      <td>1.471072</td>\n",
       "      <td>2.640288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(39, 41)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23742</th>\n",
       "      <td>21</td>\n",
       "      <td>1995-11-08</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995-11-07</td>\n",
       "      <td>1.257454</td>\n",
       "      <td>3.967424</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(15, 22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23743</th>\n",
       "      <td>21</td>\n",
       "      <td>1995-11-08</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995-11-07</td>\n",
       "      <td>1.302199</td>\n",
       "      <td>3.542703</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(13, 19)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Season       Date  HID  AID  N  POFF       Open     OddsH     OddsA  H  \\\n",
       "23739      21 1995-11-07    0   11  0     0 1995-11-06  1.274083  3.794318  0   \n",
       "23740      21 1995-11-07   17   43  0     0 1995-11-06  1.597972  2.286949  1   \n",
       "23741      21 1995-11-08   41   39  0     0 1995-11-07  1.471072  2.640288  0   \n",
       "23742      21 1995-11-08   15   22  0     0 1995-11-07  1.257454  3.967424  0   \n",
       "23743      21 1995-11-08   13   19  0     0 1995-11-07  1.302199  3.542703  1   \n",
       "\n",
       "       A SortedTID  \n",
       "23739  1   (0, 11)  \n",
       "23740  0  (17, 43)  \n",
       "23741  1  (39, 41)  \n",
       "23742  1  (15, 22)  \n",
       "23743  0  (13, 19)  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_columns = [\"Season\", \"Date\", \"HID\", \"AID\", \"N\", \"POFF\", \"Open\", \"OddsH\", \"OddsA\", \"H\", \"A\", \"SortedTID\"]\n",
    "df[\"SortedTID\"] = df[[\"HID\", \"AID\"]].apply(lambda x: tuple(sorted(x)), axis=1)\n",
    "df[meta_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature creation\n",
    "\n",
    "### Aggregated data from the whole season (!Future data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Date</th>\n",
       "      <th>HID</th>\n",
       "      <th>AID</th>\n",
       "      <th>N</th>\n",
       "      <th>POFF</th>\n",
       "      <th>Open</th>\n",
       "      <th>OddsH</th>\n",
       "      <th>OddsA</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>HFTM</th>\n",
       "      <th>HFTA</th>\n",
       "      <th>HORB</th>\n",
       "      <th>HDRB</th>\n",
       "      <th>HRB</th>\n",
       "      <th>HAST</th>\n",
       "      <th>HSTL</th>\n",
       "      <th>HBLK</th>\n",
       "      <th>HTOV</th>\n",
       "      <th>HPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>1995-11-07</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995-11-06</td>\n",
       "      <td>1.274083</td>\n",
       "      <td>3.794318</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.534884</td>\n",
       "      <td>25.046512</td>\n",
       "      <td>9.860465</td>\n",
       "      <td>30.139535</td>\n",
       "      <td>40.0</td>\n",
       "      <td>19.093023</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.860465</td>\n",
       "      <td>14.72093</td>\n",
       "      <td>20.627907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>1996-03-13</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1996-03-12</td>\n",
       "      <td>1.595060</td>\n",
       "      <td>2.293425</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>16.534884</td>\n",
       "      <td>25.046512</td>\n",
       "      <td>9.860465</td>\n",
       "      <td>30.139535</td>\n",
       "      <td>40.0</td>\n",
       "      <td>19.093023</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.860465</td>\n",
       "      <td>14.72093</td>\n",
       "      <td>20.627907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>1996-05-03</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1996-05-02</td>\n",
       "      <td>2.043143</td>\n",
       "      <td>1.731877</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.534884</td>\n",
       "      <td>25.046512</td>\n",
       "      <td>9.860465</td>\n",
       "      <td>30.139535</td>\n",
       "      <td>40.0</td>\n",
       "      <td>19.093023</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.860465</td>\n",
       "      <td>14.72093</td>\n",
       "      <td>20.627907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>1996-05-05</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1996-05-04</td>\n",
       "      <td>2.147690</td>\n",
       "      <td>1.667978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.534884</td>\n",
       "      <td>25.046512</td>\n",
       "      <td>9.860465</td>\n",
       "      <td>30.139535</td>\n",
       "      <td>40.0</td>\n",
       "      <td>19.093023</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.860465</td>\n",
       "      <td>14.72093</td>\n",
       "      <td>20.627907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>1995-12-20</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995-12-19</td>\n",
       "      <td>2.079450</td>\n",
       "      <td>1.708388</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.534884</td>\n",
       "      <td>25.046512</td>\n",
       "      <td>9.860465</td>\n",
       "      <td>30.139535</td>\n",
       "      <td>40.0</td>\n",
       "      <td>19.093023</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.860465</td>\n",
       "      <td>14.72093</td>\n",
       "      <td>20.627907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season       Date  HID  AID  N  POFF       Open     OddsH     OddsA  H  \\\n",
       "0      21 1995-11-07    0   11  0     0 1995-11-06  1.274083  3.794318  0   \n",
       "1      21 1996-03-13    0   11  0     0 1996-03-12  1.595060  2.293425  1   \n",
       "2      21 1996-05-03    0   11  0     1 1996-05-02  2.043143  1.731877  0   \n",
       "3      21 1996-05-05    0   11  0     1 1996-05-04  2.147690  1.667978  0   \n",
       "4      21 1995-12-20    0   43  0     0 1995-12-19  2.079450  1.708388  0   \n",
       "\n",
       "   ...       HFTM       HFTA      HORB       HDRB   HRB       HAST  HSTL  \\\n",
       "0  ...  16.534884  25.046512  9.860465  30.139535  40.0  19.093023   7.0   \n",
       "1  ...  16.534884  25.046512  9.860465  30.139535  40.0  19.093023   7.0   \n",
       "2  ...  16.534884  25.046512  9.860465  30.139535  40.0  19.093023   7.0   \n",
       "3  ...  16.534884  25.046512  9.860465  30.139535  40.0  19.093023   7.0   \n",
       "4  ...  16.534884  25.046512  9.860465  30.139535  40.0  19.093023   7.0   \n",
       "\n",
       "       HBLK      HTOV        HPF  \n",
       "0  5.860465  14.72093  20.627907  \n",
       "1  5.860465  14.72093  20.627907  \n",
       "2  5.860465  14.72093  20.627907  \n",
       "3  5.860465  14.72093  20.627907  \n",
       "4  5.860465  14.72093  20.627907  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seaH = df.groupby([\"Season\", \"HID\"])[columnsH].mean().reset_index()\n",
    "df_seaA = df.groupby([\"Season\", \"AID\"])[columnsA].mean().reset_index()\n",
    "\n",
    "sufix = \"_mean\"\n",
    "\n",
    "df_ml1 = pd.merge(df[meta_columns], df_seaA, on=[\"Season\", \"AID\"])\n",
    "df_ml1 = pd.merge(df_ml1, df_seaH, on=[\"Season\", \"HID\"])\n",
    "df_ml1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H ~ ASC + AFGM + AFGA + AFG3M + AFG3A + AFTM + AFTA + AORB + ADRB + ARB + AAST + ASTL + ABLK + ATOV + APF + HSC + HFGM + HFGA + HFG3M + HFG3A + HFTM + HFTA + HORB + HDRB + HRB + HAST + HSTL + HBLK + HTOV + HPF\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.569223\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>H</td>        <th>  No. Observations:  </th>   <td>  5251</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  5222</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>    28</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 05 Nov 2024</td> <th>  Pseudo R-squ.:     </th>   <td>0.1521</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:46:43</td>     <th>  Log-Likelihood:    </th>  <td> -2989.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>False</td>      <th>  LL-Null:           </th>  <td> -3525.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>7.182e-208</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -2.1731</td> <td>    1.903</td> <td>   -1.142</td> <td> 0.253</td> <td>   -5.902</td> <td>    1.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASC</th>       <td>   -0.1213</td> <td> 8551.768</td> <td>-1.42e-05</td> <td> 1.000</td> <td>-1.68e+04</td> <td> 1.68e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFGM</th>      <td>    0.0014</td> <td> 1.71e+04</td> <td> 7.94e-08</td> <td> 1.000</td> <td>-3.35e+04</td> <td> 3.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFGA</th>      <td>    0.2859</td> <td>    0.027</td> <td>   10.620</td> <td> 0.000</td> <td>    0.233</td> <td>    0.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFG3M</th>     <td>   -0.0787</td> <td> 8549.333</td> <td>-9.21e-06</td> <td> 1.000</td> <td>-1.68e+04</td> <td> 1.68e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFG3A</th>     <td>    0.0161</td> <td>    0.041</td> <td>    0.393</td> <td> 0.695</td> <td>   -0.064</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFTM</th>      <td>   -0.0481</td> <td> 8557.682</td> <td>-5.62e-06</td> <td> 1.000</td> <td>-1.68e+04</td> <td> 1.68e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFTA</th>      <td>    0.1474</td> <td>    0.041</td> <td>    3.585</td> <td> 0.000</td> <td>    0.067</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AORB</th>      <td>   -0.1339</td> <td> 3.78e+04</td> <td>-3.54e-06</td> <td> 1.000</td> <td>-7.42e+04</td> <td> 7.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ADRB</th>      <td>   -0.0700</td> <td> 3.78e+04</td> <td>-1.85e-06</td> <td> 1.000</td> <td>-7.42e+04</td> <td> 7.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ARB</th>       <td>   -0.2031</td> <td> 3.78e+04</td> <td>-5.37e-06</td> <td> 1.000</td> <td>-7.42e+04</td> <td> 7.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AAST</th>      <td>   -0.0448</td> <td>    0.024</td> <td>   -1.865</td> <td> 0.062</td> <td>   -0.092</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASTL</th>      <td>   -0.3133</td> <td>    0.053</td> <td>   -5.925</td> <td> 0.000</td> <td>   -0.417</td> <td>   -0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ABLK</th>      <td>   -0.0186</td> <td>    0.051</td> <td>   -0.361</td> <td> 0.718</td> <td>   -0.119</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ATOV</th>      <td>    0.3101</td> <td>    0.030</td> <td>   10.245</td> <td> 0.000</td> <td>    0.251</td> <td>    0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>APF</th>       <td>   -0.0197</td> <td>    0.027</td> <td>   -0.737</td> <td> 0.461</td> <td>   -0.072</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HSC</th>       <td>    0.1158</td> <td> 2.13e+04</td> <td> 5.43e-06</td> <td> 1.000</td> <td>-4.18e+04</td> <td> 4.18e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFGM</th>      <td>    0.0130</td> <td> 4.26e+04</td> <td> 3.06e-07</td> <td> 1.000</td> <td>-8.35e+04</td> <td> 8.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFGA</th>      <td>   -0.2801</td> <td>    0.024</td> <td>  -11.548</td> <td> 0.000</td> <td>   -0.328</td> <td>   -0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFG3M</th>     <td>    0.0878</td> <td> 2.13e+04</td> <td> 4.12e-06</td> <td> 1.000</td> <td>-4.18e+04</td> <td> 4.18e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFG3A</th>     <td>   -0.0202</td> <td>    0.044</td> <td>   -0.458</td> <td> 0.647</td> <td>   -0.106</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFTM</th>      <td>    0.0028</td> <td> 2.13e+04</td> <td>  1.3e-07</td> <td> 1.000</td> <td>-4.18e+04</td> <td> 4.18e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFTA</th>      <td>   -0.0856</td> <td>    0.042</td> <td>   -2.058</td> <td> 0.040</td> <td>   -0.167</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HORB</th>      <td>    0.1327</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HDRB</th>      <td>    0.0847</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HRB</th>       <td>    0.2179</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HAST</th>      <td>    0.0440</td> <td>    0.019</td> <td>    2.271</td> <td> 0.023</td> <td>    0.006</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HSTL</th>      <td>    0.2775</td> <td>    0.043</td> <td>    6.511</td> <td> 0.000</td> <td>    0.194</td> <td>    0.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HBLK</th>      <td>    0.0609</td> <td>    0.037</td> <td>    1.641</td> <td> 0.101</td> <td>   -0.012</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HTOV</th>      <td>   -0.2962</td> <td>    0.034</td> <td>   -8.692</td> <td> 0.000</td> <td>   -0.363</td> <td>   -0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HPF</th>       <td>   -0.0055</td> <td>    0.029</td> <td>   -0.189</td> <td> 0.850</td> <td>   -0.063</td> <td>    0.052</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &        H         & \\textbf{  No. Observations:  } &     5251    \\\\\n",
       "\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &     5222    \\\\\n",
       "\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &       28    \\\\\n",
       "\\textbf{Date:}            & Tue, 05 Nov 2024 & \\textbf{  Pseudo R-squ.:     } &   0.1521    \\\\\n",
       "\\textbf{Time:}            &     11:46:43     & \\textbf{  Log-Likelihood:    } &   -2989.0   \\\\\n",
       "\\textbf{converged:}       &      False       & \\textbf{  LL-Null:           } &   -3525.1   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } & 7.182e-208  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      -2.1731  &        1.903     &    -1.142  &         0.253        &       -5.902    &        1.556     \\\\\n",
       "\\textbf{ASC}       &      -0.1213  &     8551.768     & -1.42e-05  &         1.000        &    -1.68e+04    &     1.68e+04     \\\\\n",
       "\\textbf{AFGM}      &       0.0014  &     1.71e+04     &  7.94e-08  &         1.000        &    -3.35e+04    &     3.35e+04     \\\\\n",
       "\\textbf{AFGA}      &       0.2859  &        0.027     &    10.620  &         0.000        &        0.233    &        0.339     \\\\\n",
       "\\textbf{AFG3M}     &      -0.0787  &     8549.333     & -9.21e-06  &         1.000        &    -1.68e+04    &     1.68e+04     \\\\\n",
       "\\textbf{AFG3A}     &       0.0161  &        0.041     &     0.393  &         0.695        &       -0.064    &        0.096     \\\\\n",
       "\\textbf{AFTM}      &      -0.0481  &     8557.682     & -5.62e-06  &         1.000        &    -1.68e+04    &     1.68e+04     \\\\\n",
       "\\textbf{AFTA}      &       0.1474  &        0.041     &     3.585  &         0.000        &        0.067    &        0.228     \\\\\n",
       "\\textbf{AORB}      &      -0.1339  &     3.78e+04     & -3.54e-06  &         1.000        &    -7.42e+04    &     7.42e+04     \\\\\n",
       "\\textbf{ADRB}      &      -0.0700  &     3.78e+04     & -1.85e-06  &         1.000        &    -7.42e+04    &     7.42e+04     \\\\\n",
       "\\textbf{ARB}       &      -0.2031  &     3.78e+04     & -5.37e-06  &         1.000        &    -7.42e+04    &     7.42e+04     \\\\\n",
       "\\textbf{AAST}      &      -0.0448  &        0.024     &    -1.865  &         0.062        &       -0.092    &        0.002     \\\\\n",
       "\\textbf{ASTL}      &      -0.3133  &        0.053     &    -5.925  &         0.000        &       -0.417    &       -0.210     \\\\\n",
       "\\textbf{ABLK}      &      -0.0186  &        0.051     &    -0.361  &         0.718        &       -0.119    &        0.082     \\\\\n",
       "\\textbf{ATOV}      &       0.3101  &        0.030     &    10.245  &         0.000        &        0.251    &        0.369     \\\\\n",
       "\\textbf{APF}       &      -0.0197  &        0.027     &    -0.737  &         0.461        &       -0.072    &        0.033     \\\\\n",
       "\\textbf{HSC}       &       0.1158  &     2.13e+04     &  5.43e-06  &         1.000        &    -4.18e+04    &     4.18e+04     \\\\\n",
       "\\textbf{HFGM}      &       0.0130  &     4.26e+04     &  3.06e-07  &         1.000        &    -8.35e+04    &     8.35e+04     \\\\\n",
       "\\textbf{HFGA}      &      -0.2801  &        0.024     &   -11.548  &         0.000        &       -0.328    &       -0.233     \\\\\n",
       "\\textbf{HFG3M}     &       0.0878  &     2.13e+04     &  4.12e-06  &         1.000        &    -4.18e+04    &     4.18e+04     \\\\\n",
       "\\textbf{HFG3A}     &      -0.0202  &        0.044     &    -0.458  &         0.647        &       -0.106    &        0.066     \\\\\n",
       "\\textbf{HFTM}      &       0.0028  &     2.13e+04     &   1.3e-07  &         1.000        &    -4.18e+04    &     4.18e+04     \\\\\n",
       "\\textbf{HFTA}      &      -0.0856  &        0.042     &    -2.058  &         0.040        &       -0.167    &       -0.004     \\\\\n",
       "\\textbf{HORB}      &       0.1327  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{HDRB}      &       0.0847  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{HRB}       &       0.2179  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{HAST}      &       0.0440  &        0.019     &     2.271  &         0.023        &        0.006    &        0.082     \\\\\n",
       "\\textbf{HSTL}      &       0.2775  &        0.043     &     6.511  &         0.000        &        0.194    &        0.361     \\\\\n",
       "\\textbf{HBLK}      &       0.0609  &        0.037     &     1.641  &         0.101        &       -0.012    &        0.134     \\\\\n",
       "\\textbf{HTOV}      &      -0.2962  &        0.034     &    -8.692  &         0.000        &       -0.363    &       -0.229     \\\\\n",
       "\\textbf{HPF}       &      -0.0055  &        0.029     &    -0.189  &         0.850        &       -0.063    &        0.052     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      H   No. Observations:                 5251\n",
       "Model:                          Logit   Df Residuals:                     5222\n",
       "Method:                           MLE   Df Model:                           28\n",
       "Date:                Tue, 05 Nov 2024   Pseudo R-squ.:                  0.1521\n",
       "Time:                        11:46:43   Log-Likelihood:                -2989.0\n",
       "converged:                      False   LL-Null:                       -3525.1\n",
       "Covariance Type:            nonrobust   LLR p-value:                7.182e-208\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -2.1731      1.903     -1.142      0.253      -5.902       1.556\n",
       "ASC           -0.1213   8551.768  -1.42e-05      1.000   -1.68e+04    1.68e+04\n",
       "AFGM           0.0014   1.71e+04   7.94e-08      1.000   -3.35e+04    3.35e+04\n",
       "AFGA           0.2859      0.027     10.620      0.000       0.233       0.339\n",
       "AFG3M         -0.0787   8549.333  -9.21e-06      1.000   -1.68e+04    1.68e+04\n",
       "AFG3A          0.0161      0.041      0.393      0.695      -0.064       0.096\n",
       "AFTM          -0.0481   8557.682  -5.62e-06      1.000   -1.68e+04    1.68e+04\n",
       "AFTA           0.1474      0.041      3.585      0.000       0.067       0.228\n",
       "AORB          -0.1339   3.78e+04  -3.54e-06      1.000   -7.42e+04    7.42e+04\n",
       "ADRB          -0.0700   3.78e+04  -1.85e-06      1.000   -7.42e+04    7.42e+04\n",
       "ARB           -0.2031   3.78e+04  -5.37e-06      1.000   -7.42e+04    7.42e+04\n",
       "AAST          -0.0448      0.024     -1.865      0.062      -0.092       0.002\n",
       "ASTL          -0.3133      0.053     -5.925      0.000      -0.417      -0.210\n",
       "ABLK          -0.0186      0.051     -0.361      0.718      -0.119       0.082\n",
       "ATOV           0.3101      0.030     10.245      0.000       0.251       0.369\n",
       "APF           -0.0197      0.027     -0.737      0.461      -0.072       0.033\n",
       "HSC            0.1158   2.13e+04   5.43e-06      1.000   -4.18e+04    4.18e+04\n",
       "HFGM           0.0130   4.26e+04   3.06e-07      1.000   -8.35e+04    8.35e+04\n",
       "HFGA          -0.2801      0.024    -11.548      0.000      -0.328      -0.233\n",
       "HFG3M          0.0878   2.13e+04   4.12e-06      1.000   -4.18e+04    4.18e+04\n",
       "HFG3A         -0.0202      0.044     -0.458      0.647      -0.106       0.066\n",
       "HFTM           0.0028   2.13e+04    1.3e-07      1.000   -4.18e+04    4.18e+04\n",
       "HFTA          -0.0856      0.042     -2.058      0.040      -0.167      -0.004\n",
       "HORB           0.1327        nan        nan        nan         nan         nan\n",
       "HDRB           0.0847        nan        nan        nan         nan         nan\n",
       "HRB            0.2179        nan        nan        nan         nan         nan\n",
       "HAST           0.0440      0.019      2.271      0.023       0.006       0.082\n",
       "HSTL           0.2775      0.043      6.511      0.000       0.194       0.361\n",
       "HBLK           0.0609      0.037      1.641      0.101      -0.012       0.134\n",
       "HTOV          -0.2962      0.034     -8.692      0.000      -0.363      -0.229\n",
       "HPF           -0.0055      0.029     -0.189      0.850      -0.063       0.052\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = columnsA + columnsH\n",
    "formula = \"H ~ \" + \" + \".join(features)\n",
    "print(formula)\n",
    "\n",
    "model = smf.logit(formula=formula, data=df_ml1)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H ~ HFGM + HFGA + HFG3M + HFG3A + HFTM + HFTA + HORB + HDRB + HAST + HSTL + HBLK + HTOV + AFGM + AFGA + AFG3M + AFG3A + AFTM + AFTA + AORB + ADRB + AAST + ASTL + ABLK + ATOV\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.569278\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>H</td>        <th>  No. Observations:  </th>   <td>  5251</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  5226</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>    24</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 05 Nov 2024</td> <th>  Pseudo R-squ.:     </th>   <td>0.1520</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>16:44:32</td>     <th>  Log-Likelihood:    </th>  <td> -2989.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -3525.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>5.145e-211</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -2.6061</td> <td>    1.803</td> <td>   -1.446</td> <td> 0.148</td> <td>   -6.140</td> <td>    0.927</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFGM</th>      <td>    0.2460</td> <td>    0.037</td> <td>    6.703</td> <td> 0.000</td> <td>    0.174</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFGA</th>      <td>   -0.2809</td> <td>    0.023</td> <td>  -11.995</td> <td> 0.000</td> <td>   -0.327</td> <td>   -0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFG3M</th>     <td>    0.2011</td> <td>    0.107</td> <td>    1.883</td> <td> 0.060</td> <td>   -0.008</td> <td>    0.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFG3A</th>     <td>   -0.0194</td> <td>    0.044</td> <td>   -0.443</td> <td> 0.658</td> <td>   -0.105</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFTM</th>      <td>    0.1183</td> <td>    0.047</td> <td>    2.516</td> <td> 0.012</td> <td>    0.026</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFTA</th>      <td>   -0.0869</td> <td>    0.041</td> <td>   -2.125</td> <td> 0.034</td> <td>   -0.167</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HORB</th>      <td>    0.3506</td> <td>    0.040</td> <td>    8.751</td> <td> 0.000</td> <td>    0.272</td> <td>    0.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HDRB</th>      <td>    0.3047</td> <td>    0.028</td> <td>   10.750</td> <td> 0.000</td> <td>    0.249</td> <td>    0.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HAST</th>      <td>    0.0429</td> <td>    0.019</td> <td>    2.286</td> <td> 0.022</td> <td>    0.006</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HSTL</th>      <td>    0.2777</td> <td>    0.043</td> <td>    6.517</td> <td> 0.000</td> <td>    0.194</td> <td>    0.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HBLK</th>      <td>    0.0616</td> <td>    0.037</td> <td>    1.666</td> <td> 0.096</td> <td>   -0.011</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HTOV</th>      <td>   -0.2986</td> <td>    0.033</td> <td>   -9.084</td> <td> 0.000</td> <td>   -0.363</td> <td>   -0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFGM</th>      <td>   -0.2393</td> <td>    0.040</td> <td>   -5.930</td> <td> 0.000</td> <td>   -0.318</td> <td>   -0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFGA</th>      <td>    0.2866</td> <td>    0.027</td> <td>   10.657</td> <td> 0.000</td> <td>    0.234</td> <td>    0.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFG3M</th>     <td>   -0.2013</td> <td>    0.101</td> <td>   -1.992</td> <td> 0.046</td> <td>   -0.399</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFG3A</th>     <td>    0.0155</td> <td>    0.041</td> <td>    0.379</td> <td> 0.704</td> <td>   -0.065</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFTM</th>      <td>   -0.1733</td> <td>    0.050</td> <td>   -3.471</td> <td> 0.001</td> <td>   -0.271</td> <td>   -0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFTA</th>      <td>    0.1464</td> <td>    0.041</td> <td>    3.564</td> <td> 0.000</td> <td>    0.066</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AORB</th>      <td>   -0.3406</td> <td>    0.044</td> <td>   -7.788</td> <td> 0.000</td> <td>   -0.426</td> <td>   -0.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ADRB</th>      <td>   -0.2696</td> <td>    0.029</td> <td>   -9.348</td> <td> 0.000</td> <td>   -0.326</td> <td>   -0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AAST</th>      <td>   -0.0467</td> <td>    0.024</td> <td>   -1.954</td> <td> 0.051</td> <td>   -0.093</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASTL</th>      <td>   -0.3154</td> <td>    0.053</td> <td>   -5.974</td> <td> 0.000</td> <td>   -0.419</td> <td>   -0.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ABLK</th>      <td>   -0.0164</td> <td>    0.051</td> <td>   -0.319</td> <td> 0.749</td> <td>   -0.117</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ATOV</th>      <td>    0.3032</td> <td>    0.029</td> <td>   10.519</td> <td> 0.000</td> <td>    0.247</td> <td>    0.360</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &        H         & \\textbf{  No. Observations:  } &     5251    \\\\\n",
       "\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &     5226    \\\\\n",
       "\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &       24    \\\\\n",
       "\\textbf{Date:}            & Tue, 05 Nov 2024 & \\textbf{  Pseudo R-squ.:     } &   0.1520    \\\\\n",
       "\\textbf{Time:}            &     16:44:32     & \\textbf{  Log-Likelihood:    } &   -2989.3   \\\\\n",
       "\\textbf{converged:}       &       True       & \\textbf{  LL-Null:           } &   -3525.1   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } & 5.145e-211  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      -2.6061  &        1.803     &    -1.446  &         0.148        &       -6.140    &        0.927     \\\\\n",
       "\\textbf{HFGM}      &       0.2460  &        0.037     &     6.703  &         0.000        &        0.174    &        0.318     \\\\\n",
       "\\textbf{HFGA}      &      -0.2809  &        0.023     &   -11.995  &         0.000        &       -0.327    &       -0.235     \\\\\n",
       "\\textbf{HFG3M}     &       0.2011  &        0.107     &     1.883  &         0.060        &       -0.008    &        0.410     \\\\\n",
       "\\textbf{HFG3A}     &      -0.0194  &        0.044     &    -0.443  &         0.658        &       -0.105    &        0.066     \\\\\n",
       "\\textbf{HFTM}      &       0.1183  &        0.047     &     2.516  &         0.012        &        0.026    &        0.210     \\\\\n",
       "\\textbf{HFTA}      &      -0.0869  &        0.041     &    -2.125  &         0.034        &       -0.167    &       -0.007     \\\\\n",
       "\\textbf{HORB}      &       0.3506  &        0.040     &     8.751  &         0.000        &        0.272    &        0.429     \\\\\n",
       "\\textbf{HDRB}      &       0.3047  &        0.028     &    10.750  &         0.000        &        0.249    &        0.360     \\\\\n",
       "\\textbf{HAST}      &       0.0429  &        0.019     &     2.286  &         0.022        &        0.006    &        0.080     \\\\\n",
       "\\textbf{HSTL}      &       0.2777  &        0.043     &     6.517  &         0.000        &        0.194    &        0.361     \\\\\n",
       "\\textbf{HBLK}      &       0.0616  &        0.037     &     1.666  &         0.096        &       -0.011    &        0.134     \\\\\n",
       "\\textbf{HTOV}      &      -0.2986  &        0.033     &    -9.084  &         0.000        &       -0.363    &       -0.234     \\\\\n",
       "\\textbf{AFGM}      &      -0.2393  &        0.040     &    -5.930  &         0.000        &       -0.318    &       -0.160     \\\\\n",
       "\\textbf{AFGA}      &       0.2866  &        0.027     &    10.657  &         0.000        &        0.234    &        0.339     \\\\\n",
       "\\textbf{AFG3M}     &      -0.2013  &        0.101     &    -1.992  &         0.046        &       -0.399    &       -0.003     \\\\\n",
       "\\textbf{AFG3A}     &       0.0155  &        0.041     &     0.379  &         0.704        &       -0.065    &        0.096     \\\\\n",
       "\\textbf{AFTM}      &      -0.1733  &        0.050     &    -3.471  &         0.001        &       -0.271    &       -0.075     \\\\\n",
       "\\textbf{AFTA}      &       0.1464  &        0.041     &     3.564  &         0.000        &        0.066    &        0.227     \\\\\n",
       "\\textbf{AORB}      &      -0.3406  &        0.044     &    -7.788  &         0.000        &       -0.426    &       -0.255     \\\\\n",
       "\\textbf{ADRB}      &      -0.2696  &        0.029     &    -9.348  &         0.000        &       -0.326    &       -0.213     \\\\\n",
       "\\textbf{AAST}      &      -0.0467  &        0.024     &    -1.954  &         0.051        &       -0.093    &        0.000     \\\\\n",
       "\\textbf{ASTL}      &      -0.3154  &        0.053     &    -5.974  &         0.000        &       -0.419    &       -0.212     \\\\\n",
       "\\textbf{ABLK}      &      -0.0164  &        0.051     &    -0.319  &         0.749        &       -0.117    &        0.084     \\\\\n",
       "\\textbf{ATOV}      &       0.3032  &        0.029     &    10.519  &         0.000        &        0.247    &        0.360     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      H   No. Observations:                 5251\n",
       "Model:                          Logit   Df Residuals:                     5226\n",
       "Method:                           MLE   Df Model:                           24\n",
       "Date:                Tue, 05 Nov 2024   Pseudo R-squ.:                  0.1520\n",
       "Time:                        16:44:32   Log-Likelihood:                -2989.3\n",
       "converged:                       True   LL-Null:                       -3525.1\n",
       "Covariance Type:            nonrobust   LLR p-value:                5.145e-211\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -2.6061      1.803     -1.446      0.148      -6.140       0.927\n",
       "HFGM           0.2460      0.037      6.703      0.000       0.174       0.318\n",
       "HFGA          -0.2809      0.023    -11.995      0.000      -0.327      -0.235\n",
       "HFG3M          0.2011      0.107      1.883      0.060      -0.008       0.410\n",
       "HFG3A         -0.0194      0.044     -0.443      0.658      -0.105       0.066\n",
       "HFTM           0.1183      0.047      2.516      0.012       0.026       0.210\n",
       "HFTA          -0.0869      0.041     -2.125      0.034      -0.167      -0.007\n",
       "HORB           0.3506      0.040      8.751      0.000       0.272       0.429\n",
       "HDRB           0.3047      0.028     10.750      0.000       0.249       0.360\n",
       "HAST           0.0429      0.019      2.286      0.022       0.006       0.080\n",
       "HSTL           0.2777      0.043      6.517      0.000       0.194       0.361\n",
       "HBLK           0.0616      0.037      1.666      0.096      -0.011       0.134\n",
       "HTOV          -0.2986      0.033     -9.084      0.000      -0.363      -0.234\n",
       "AFGM          -0.2393      0.040     -5.930      0.000      -0.318      -0.160\n",
       "AFGA           0.2866      0.027     10.657      0.000       0.234       0.339\n",
       "AFG3M         -0.2013      0.101     -1.992      0.046      -0.399      -0.003\n",
       "AFG3A          0.0155      0.041      0.379      0.704      -0.065       0.096\n",
       "AFTM          -0.1733      0.050     -3.471      0.001      -0.271      -0.075\n",
       "AFTA           0.1464      0.041      3.564      0.000       0.066       0.227\n",
       "AORB          -0.3406      0.044     -7.788      0.000      -0.426      -0.255\n",
       "ADRB          -0.2696      0.029     -9.348      0.000      -0.326      -0.213\n",
       "AAST          -0.0467      0.024     -1.954      0.051      -0.093       0.000\n",
       "ASTL          -0.3154      0.053     -5.974      0.000      -0.419      -0.212\n",
       "ABLK          -0.0164      0.051     -0.319      0.749      -0.117       0.084\n",
       "ATOV           0.3032      0.029     10.519      0.000       0.247       0.360\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    \"HFGM\", \"HFGA\", \"HFG3M\", \"HFG3A\", \"HFTM\", \"HFTA\", \"HORB\", \"HDRB\", \"HAST\", \"HSTL\", \"HBLK\", \"HTOV\",\n",
    "    \"AFGM\", \"AFGA\", \"AFG3M\", \"AFG3A\", \"AFTM\", \"AFTA\", \"AORB\", \"ADRB\", \"AAST\", \"ASTL\", \"ABLK\", \"ATOV\",\n",
    "]\n",
    "# features = [\n",
    "#     \"HFGM\", \"HFGA\", \"HFG3M\", \"HFTM\", \"HFTA\", \"HORB\", \"HDRB\", \"HAST\", \"HSTL\", \"HBLK\", \"HTOV\",\n",
    "#     \"AFGM\", \"AFGA\", \"AFG3M\", \"AFTM\", \"AFTA\", \"AORB\", \"ADRB\", \"AAST\", \"ASTL\", \"ABLK\", \"ATOV\",\n",
    "# ]\n",
    "# features = [\n",
    "#     \"HFGM\", \"HFGA\", \"HFG3M\", \"HFTM\", \"HFTA\", \"HORB\", \"HDRB\", \"HAST\", \"HSTL\", \"HTOV\",\n",
    "#     \"AFGM\", \"AFGA\", \"AFG3M\", \"AFTM\", \"AFTA\", \"AORB\", \"ADRB\", \"AAST\", \"ASTL\", \"ATOV\",\n",
    "# ]\n",
    "\n",
    "formula = \"H ~ \" + \" + \".join(features)\n",
    "print(formula)\n",
    "\n",
    "model = smf.logit(formula=formula, data=df_ml1)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated data from the last season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LastSeason</th>\n",
       "      <th>Date</th>\n",
       "      <th>HID</th>\n",
       "      <th>AID</th>\n",
       "      <th>N</th>\n",
       "      <th>POFF</th>\n",
       "      <th>Open</th>\n",
       "      <th>OddsH</th>\n",
       "      <th>OddsA</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>HFTM</th>\n",
       "      <th>HFTA</th>\n",
       "      <th>HORB</th>\n",
       "      <th>HDRB</th>\n",
       "      <th>HRB</th>\n",
       "      <th>HAST</th>\n",
       "      <th>HSTL</th>\n",
       "      <th>HBLK</th>\n",
       "      <th>HTOV</th>\n",
       "      <th>HPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>1996-11-05</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1996-11-04</td>\n",
       "      <td>1.498635</td>\n",
       "      <td>2.548866</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.804348</td>\n",
       "      <td>28.173913</td>\n",
       "      <td>11.521739</td>\n",
       "      <td>30.565217</td>\n",
       "      <td>42.086957</td>\n",
       "      <td>25.673913</td>\n",
       "      <td>9.456522</td>\n",
       "      <td>6.413043</td>\n",
       "      <td>15.23913</td>\n",
       "      <td>23.847826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>1996-12-05</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1996-12-04</td>\n",
       "      <td>1.529088</td>\n",
       "      <td>2.458521</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19.804348</td>\n",
       "      <td>28.173913</td>\n",
       "      <td>11.521739</td>\n",
       "      <td>30.565217</td>\n",
       "      <td>42.086957</td>\n",
       "      <td>25.673913</td>\n",
       "      <td>9.456522</td>\n",
       "      <td>6.413043</td>\n",
       "      <td>15.23913</td>\n",
       "      <td>23.847826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>1997-03-28</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1997-03-27</td>\n",
       "      <td>1.672292</td>\n",
       "      <td>2.140028</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.804348</td>\n",
       "      <td>28.173913</td>\n",
       "      <td>11.521739</td>\n",
       "      <td>30.565217</td>\n",
       "      <td>42.086957</td>\n",
       "      <td>25.673913</td>\n",
       "      <td>9.456522</td>\n",
       "      <td>6.413043</td>\n",
       "      <td>15.23913</td>\n",
       "      <td>23.847826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>1997-03-09</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1997-03-08</td>\n",
       "      <td>1.268885</td>\n",
       "      <td>3.846260</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19.804348</td>\n",
       "      <td>28.173913</td>\n",
       "      <td>11.521739</td>\n",
       "      <td>30.565217</td>\n",
       "      <td>42.086957</td>\n",
       "      <td>25.673913</td>\n",
       "      <td>9.456522</td>\n",
       "      <td>6.413043</td>\n",
       "      <td>15.23913</td>\n",
       "      <td>23.847826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>1997-04-03</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1997-04-02</td>\n",
       "      <td>1.243589</td>\n",
       "      <td>4.128690</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19.804348</td>\n",
       "      <td>28.173913</td>\n",
       "      <td>11.521739</td>\n",
       "      <td>30.565217</td>\n",
       "      <td>42.086957</td>\n",
       "      <td>25.673913</td>\n",
       "      <td>9.456522</td>\n",
       "      <td>6.413043</td>\n",
       "      <td>15.23913</td>\n",
       "      <td>23.847826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LastSeason       Date  HID  AID  N  POFF       Open     OddsH     OddsA  H  \\\n",
       "0          21 1996-11-05    8   12  0     0 1996-11-04  1.498635  2.548866  0   \n",
       "1          21 1996-12-05    8    1  0     0 1996-12-04  1.529088  2.458521  1   \n",
       "2          21 1997-03-28    8    1  0     0 1997-03-27  1.672292  2.140028  0   \n",
       "3          21 1997-03-09    8   24  0     0 1997-03-08  1.268885  3.846260  1   \n",
       "4          21 1997-04-03    8   24  0     0 1997-04-02  1.243589  4.128690  1   \n",
       "\n",
       "   ...       HFTM       HFTA       HORB       HDRB        HRB       HAST  \\\n",
       "0  ...  19.804348  28.173913  11.521739  30.565217  42.086957  25.673913   \n",
       "1  ...  19.804348  28.173913  11.521739  30.565217  42.086957  25.673913   \n",
       "2  ...  19.804348  28.173913  11.521739  30.565217  42.086957  25.673913   \n",
       "3  ...  19.804348  28.173913  11.521739  30.565217  42.086957  25.673913   \n",
       "4  ...  19.804348  28.173913  11.521739  30.565217  42.086957  25.673913   \n",
       "\n",
       "       HSTL      HBLK      HTOV        HPF  \n",
       "0  9.456522  6.413043  15.23913  23.847826  \n",
       "1  9.456522  6.413043  15.23913  23.847826  \n",
       "2  9.456522  6.413043  15.23913  23.847826  \n",
       "3  9.456522  6.413043  15.23913  23.847826  \n",
       "4  9.456522  6.413043  15.23913  23.847826  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"LastSeason\"] = df[\"Season\"] - 1\n",
    "\n",
    "meta_columns = [\"LastSeason\", \"Date\", \"HID\", \"AID\", \"N\", \"POFF\", \"Open\", \"OddsH\", \"OddsA\", \"H\", \"A\", \"SortedTID\"]\n",
    "\n",
    "df_ml2 = pd.merge(df[meta_columns], df_seaA, left_on=[\"LastSeason\", \"AID\"], right_on=[\"Season\", \"AID\"])\n",
    "df_ml2 = pd.merge(df_ml2, df_seaH, left_on=[\"LastSeason\", \"HID\"], right_on=[\"Season\", \"HID\"])\n",
    "df_ml2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H ~ HFGM + HFGA + HFG3M + HFG3A + HFTM + HFTA + HORB + HDRB + HAST + HSTL + HBLK + HTOV + AFGM + AFGA + AFG3M + AFG3A + AFTM + AFTA + AORB + ADRB + AAST + ASTL + ABLK + ATOV\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.622379\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>H</td>        <th>  No. Observations:  </th>  <td>  3942</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  3917</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    24</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 05 Nov 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.07114</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:54:16</td>     <th>  Log-Likelihood:    </th> <td> -2453.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -2641.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>6.740e-65</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -3.1014</td> <td>    1.967</td> <td>   -1.577</td> <td> 0.115</td> <td>   -6.957</td> <td>    0.754</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFGM</th>      <td>   -0.0204</td> <td>    0.041</td> <td>   -0.503</td> <td> 0.615</td> <td>   -0.100</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFGA</th>      <td>   -0.1023</td> <td>    0.026</td> <td>   -3.963</td> <td> 0.000</td> <td>   -0.153</td> <td>   -0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFG3M</th>     <td>    0.7550</td> <td>    0.130</td> <td>    5.796</td> <td> 0.000</td> <td>    0.500</td> <td>    1.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFG3A</th>     <td>   -0.2587</td> <td>    0.053</td> <td>   -4.851</td> <td> 0.000</td> <td>   -0.363</td> <td>   -0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFTM</th>      <td>   -0.1094</td> <td>    0.050</td> <td>   -2.168</td> <td> 0.030</td> <td>   -0.208</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFTA</th>      <td>    0.0885</td> <td>    0.046</td> <td>    1.944</td> <td> 0.052</td> <td>   -0.001</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HORB</th>      <td>    0.1957</td> <td>    0.045</td> <td>    4.322</td> <td> 0.000</td> <td>    0.107</td> <td>    0.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HDRB</th>      <td>    0.1757</td> <td>    0.029</td> <td>    6.031</td> <td> 0.000</td> <td>    0.119</td> <td>    0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HAST</th>      <td>    0.0990</td> <td>    0.021</td> <td>    4.733</td> <td> 0.000</td> <td>    0.058</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HSTL</th>      <td>    0.1420</td> <td>    0.051</td> <td>    2.784</td> <td> 0.005</td> <td>    0.042</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HBLK</th>      <td>    0.0561</td> <td>    0.039</td> <td>    1.428</td> <td> 0.153</td> <td>   -0.021</td> <td>    0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HTOV</th>      <td>   -0.0592</td> <td>    0.038</td> <td>   -1.564</td> <td> 0.118</td> <td>   -0.133</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFGM</th>      <td>   -0.2179</td> <td>    0.045</td> <td>   -4.890</td> <td> 0.000</td> <td>   -0.305</td> <td>   -0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFGA</th>      <td>    0.1984</td> <td>    0.028</td> <td>    7.113</td> <td> 0.000</td> <td>    0.144</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFG3M</th>     <td>    0.1004</td> <td>    0.111</td> <td>    0.904</td> <td> 0.366</td> <td>   -0.117</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFG3A</th>     <td>   -0.0754</td> <td>    0.045</td> <td>   -1.692</td> <td> 0.091</td> <td>   -0.163</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFTM</th>      <td>    0.0390</td> <td>    0.055</td> <td>    0.708</td> <td> 0.479</td> <td>   -0.069</td> <td>    0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFTA</th>      <td>   -0.0364</td> <td>    0.045</td> <td>   -0.805</td> <td> 0.421</td> <td>   -0.125</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AORB</th>      <td>   -0.1849</td> <td>    0.050</td> <td>   -3.721</td> <td> 0.000</td> <td>   -0.282</td> <td>   -0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ADRB</th>      <td>   -0.1461</td> <td>    0.033</td> <td>   -4.468</td> <td> 0.000</td> <td>   -0.210</td> <td>   -0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AAST</th>      <td>    0.0281</td> <td>    0.028</td> <td>    0.989</td> <td> 0.323</td> <td>   -0.028</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASTL</th>      <td>   -0.1009</td> <td>    0.060</td> <td>   -1.689</td> <td> 0.091</td> <td>   -0.218</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ABLK</th>      <td>   -0.1776</td> <td>    0.059</td> <td>   -3.000</td> <td> 0.003</td> <td>   -0.294</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ATOV</th>      <td>    0.1333</td> <td>    0.030</td> <td>    4.519</td> <td> 0.000</td> <td>    0.076</td> <td>    0.191</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &        H         & \\textbf{  No. Observations:  } &     3942    \\\\\n",
       "\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &     3917    \\\\\n",
       "\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &       24    \\\\\n",
       "\\textbf{Date:}            & Tue, 05 Nov 2024 & \\textbf{  Pseudo R-squ.:     } &  0.07114    \\\\\n",
       "\\textbf{Time:}            &     11:54:16     & \\textbf{  Log-Likelihood:    } &   -2453.4   \\\\\n",
       "\\textbf{converged:}       &       True       & \\textbf{  LL-Null:           } &   -2641.3   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } & 6.740e-65   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      -3.1014  &        1.967     &    -1.577  &         0.115        &       -6.957    &        0.754     \\\\\n",
       "\\textbf{HFGM}      &      -0.0204  &        0.041     &    -0.503  &         0.615        &       -0.100    &        0.059     \\\\\n",
       "\\textbf{HFGA}      &      -0.1023  &        0.026     &    -3.963  &         0.000        &       -0.153    &       -0.052     \\\\\n",
       "\\textbf{HFG3M}     &       0.7550  &        0.130     &     5.796  &         0.000        &        0.500    &        1.010     \\\\\n",
       "\\textbf{HFG3A}     &      -0.2587  &        0.053     &    -4.851  &         0.000        &       -0.363    &       -0.154     \\\\\n",
       "\\textbf{HFTM}      &      -0.1094  &        0.050     &    -2.168  &         0.030        &       -0.208    &       -0.010     \\\\\n",
       "\\textbf{HFTA}      &       0.0885  &        0.046     &     1.944  &         0.052        &       -0.001    &        0.178     \\\\\n",
       "\\textbf{HORB}      &       0.1957  &        0.045     &     4.322  &         0.000        &        0.107    &        0.284     \\\\\n",
       "\\textbf{HDRB}      &       0.1757  &        0.029     &     6.031  &         0.000        &        0.119    &        0.233     \\\\\n",
       "\\textbf{HAST}      &       0.0990  &        0.021     &     4.733  &         0.000        &        0.058    &        0.140     \\\\\n",
       "\\textbf{HSTL}      &       0.1420  &        0.051     &     2.784  &         0.005        &        0.042    &        0.242     \\\\\n",
       "\\textbf{HBLK}      &       0.0561  &        0.039     &     1.428  &         0.153        &       -0.021    &        0.133     \\\\\n",
       "\\textbf{HTOV}      &      -0.0592  &        0.038     &    -1.564  &         0.118        &       -0.133    &        0.015     \\\\\n",
       "\\textbf{AFGM}      &      -0.2179  &        0.045     &    -4.890  &         0.000        &       -0.305    &       -0.131     \\\\\n",
       "\\textbf{AFGA}      &       0.1984  &        0.028     &     7.113  &         0.000        &        0.144    &        0.253     \\\\\n",
       "\\textbf{AFG3M}     &       0.1004  &        0.111     &     0.904  &         0.366        &       -0.117    &        0.318     \\\\\n",
       "\\textbf{AFG3A}     &      -0.0754  &        0.045     &    -1.692  &         0.091        &       -0.163    &        0.012     \\\\\n",
       "\\textbf{AFTM}      &       0.0390  &        0.055     &     0.708  &         0.479        &       -0.069    &        0.147     \\\\\n",
       "\\textbf{AFTA}      &      -0.0364  &        0.045     &    -0.805  &         0.421        &       -0.125    &        0.052     \\\\\n",
       "\\textbf{AORB}      &      -0.1849  &        0.050     &    -3.721  &         0.000        &       -0.282    &       -0.087     \\\\\n",
       "\\textbf{ADRB}      &      -0.1461  &        0.033     &    -4.468  &         0.000        &       -0.210    &       -0.082     \\\\\n",
       "\\textbf{AAST}      &       0.0281  &        0.028     &     0.989  &         0.323        &       -0.028    &        0.084     \\\\\n",
       "\\textbf{ASTL}      &      -0.1009  &        0.060     &    -1.689  &         0.091        &       -0.218    &        0.016     \\\\\n",
       "\\textbf{ABLK}      &      -0.1776  &        0.059     &    -3.000  &         0.003        &       -0.294    &       -0.062     \\\\\n",
       "\\textbf{ATOV}      &       0.1333  &        0.030     &     4.519  &         0.000        &        0.076    &        0.191     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      H   No. Observations:                 3942\n",
       "Model:                          Logit   Df Residuals:                     3917\n",
       "Method:                           MLE   Df Model:                           24\n",
       "Date:                Tue, 05 Nov 2024   Pseudo R-squ.:                 0.07114\n",
       "Time:                        11:54:16   Log-Likelihood:                -2453.4\n",
       "converged:                       True   LL-Null:                       -2641.3\n",
       "Covariance Type:            nonrobust   LLR p-value:                 6.740e-65\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -3.1014      1.967     -1.577      0.115      -6.957       0.754\n",
       "HFGM          -0.0204      0.041     -0.503      0.615      -0.100       0.059\n",
       "HFGA          -0.1023      0.026     -3.963      0.000      -0.153      -0.052\n",
       "HFG3M          0.7550      0.130      5.796      0.000       0.500       1.010\n",
       "HFG3A         -0.2587      0.053     -4.851      0.000      -0.363      -0.154\n",
       "HFTM          -0.1094      0.050     -2.168      0.030      -0.208      -0.010\n",
       "HFTA           0.0885      0.046      1.944      0.052      -0.001       0.178\n",
       "HORB           0.1957      0.045      4.322      0.000       0.107       0.284\n",
       "HDRB           0.1757      0.029      6.031      0.000       0.119       0.233\n",
       "HAST           0.0990      0.021      4.733      0.000       0.058       0.140\n",
       "HSTL           0.1420      0.051      2.784      0.005       0.042       0.242\n",
       "HBLK           0.0561      0.039      1.428      0.153      -0.021       0.133\n",
       "HTOV          -0.0592      0.038     -1.564      0.118      -0.133       0.015\n",
       "AFGM          -0.2179      0.045     -4.890      0.000      -0.305      -0.131\n",
       "AFGA           0.1984      0.028      7.113      0.000       0.144       0.253\n",
       "AFG3M          0.1004      0.111      0.904      0.366      -0.117       0.318\n",
       "AFG3A         -0.0754      0.045     -1.692      0.091      -0.163       0.012\n",
       "AFTM           0.0390      0.055      0.708      0.479      -0.069       0.147\n",
       "AFTA          -0.0364      0.045     -0.805      0.421      -0.125       0.052\n",
       "AORB          -0.1849      0.050     -3.721      0.000      -0.282      -0.087\n",
       "ADRB          -0.1461      0.033     -4.468      0.000      -0.210      -0.082\n",
       "AAST           0.0281      0.028      0.989      0.323      -0.028       0.084\n",
       "ASTL          -0.1009      0.060     -1.689      0.091      -0.218       0.016\n",
       "ABLK          -0.1776      0.059     -3.000      0.003      -0.294      -0.062\n",
       "ATOV           0.1333      0.030      4.519      0.000       0.076       0.191\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    \"HFGM\", \"HFGA\", \"HFG3M\", \"HFG3A\", \"HFTM\", \"HFTA\", \"HORB\", \"HDRB\", \"HAST\", \"HSTL\", \"HBLK\", \"HTOV\",\n",
    "    \"AFGM\", \"AFGA\", \"AFG3M\", \"AFG3A\", \"AFTM\", \"AFTA\", \"AORB\", \"ADRB\", \"AAST\", \"ASTL\", \"ABLK\", \"ATOV\",\n",
    "]\n",
    "# features = [\n",
    "#     \"HFGM\", \"HFGA\", \"HFG3M\", \"HFTM\", \"HFTA\", \"HORB\", \"HDRB\", \"HAST\", \"HSTL\", \"HTOV\",\n",
    "#     \"AFGM\", \"AFGA\", \"AFG3M\", \"AFTM\", \"AFTA\", \"AORB\", \"ADRB\", \"AAST\", \"ASTL\", \"ATOV\",\n",
    "# ]\n",
    "\n",
    "formula = \"H ~ \" + \" + \".join(features)\n",
    "print(formula)\n",
    "\n",
    "\n",
    "model = smf.logit(formula=formula, data=df_ml2)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling window last N games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LastSeason</th>\n",
       "      <th>Date</th>\n",
       "      <th>HID</th>\n",
       "      <th>AID</th>\n",
       "      <th>N</th>\n",
       "      <th>POFF</th>\n",
       "      <th>Open</th>\n",
       "      <th>OddsH</th>\n",
       "      <th>OddsA</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>HFTM</th>\n",
       "      <th>HFTA</th>\n",
       "      <th>HORB</th>\n",
       "      <th>HDRB</th>\n",
       "      <th>HRB</th>\n",
       "      <th>HAST</th>\n",
       "      <th>HSTL</th>\n",
       "      <th>HBLK</th>\n",
       "      <th>HTOV</th>\n",
       "      <th>HPF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24473</th>\n",
       "      <td>20</td>\n",
       "      <td>1996-02-15</td>\n",
       "      <td>39</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1996-02-14</td>\n",
       "      <td>1.351329</td>\n",
       "      <td>3.195158</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>16.00</td>\n",
       "      <td>22.12</td>\n",
       "      <td>11.64</td>\n",
       "      <td>31.52</td>\n",
       "      <td>43.16</td>\n",
       "      <td>18.36</td>\n",
       "      <td>6.44</td>\n",
       "      <td>4.56</td>\n",
       "      <td>13.44</td>\n",
       "      <td>19.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24478</th>\n",
       "      <td>20</td>\n",
       "      <td>1996-02-16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1996-02-15</td>\n",
       "      <td>1.856686</td>\n",
       "      <td>1.882726</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>23.00</td>\n",
       "      <td>29.64</td>\n",
       "      <td>9.48</td>\n",
       "      <td>28.80</td>\n",
       "      <td>38.28</td>\n",
       "      <td>21.64</td>\n",
       "      <td>7.08</td>\n",
       "      <td>5.52</td>\n",
       "      <td>15.88</td>\n",
       "      <td>22.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24479</th>\n",
       "      <td>20</td>\n",
       "      <td>1996-02-16</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1996-02-15</td>\n",
       "      <td>1.489967</td>\n",
       "      <td>2.576553</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>17.96</td>\n",
       "      <td>26.56</td>\n",
       "      <td>13.16</td>\n",
       "      <td>30.80</td>\n",
       "      <td>43.96</td>\n",
       "      <td>21.56</td>\n",
       "      <td>6.96</td>\n",
       "      <td>5.44</td>\n",
       "      <td>14.56</td>\n",
       "      <td>21.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24481</th>\n",
       "      <td>20</td>\n",
       "      <td>1996-02-16</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1996-02-15</td>\n",
       "      <td>2.481544</td>\n",
       "      <td>1.520993</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>21.20</td>\n",
       "      <td>30.56</td>\n",
       "      <td>11.88</td>\n",
       "      <td>29.64</td>\n",
       "      <td>41.52</td>\n",
       "      <td>18.32</td>\n",
       "      <td>7.24</td>\n",
       "      <td>4.56</td>\n",
       "      <td>17.44</td>\n",
       "      <td>22.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24485</th>\n",
       "      <td>20</td>\n",
       "      <td>1996-02-16</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1996-02-15</td>\n",
       "      <td>1.251116</td>\n",
       "      <td>4.039071</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20.68</td>\n",
       "      <td>25.16</td>\n",
       "      <td>11.68</td>\n",
       "      <td>31.92</td>\n",
       "      <td>43.60</td>\n",
       "      <td>21.16</td>\n",
       "      <td>6.96</td>\n",
       "      <td>5.44</td>\n",
       "      <td>13.96</td>\n",
       "      <td>21.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LastSeason       Date  HID  AID  N  POFF       Open     OddsH  \\\n",
       "24473          20 1996-02-15   39   22  0     0 1996-02-14  1.351329   \n",
       "24478          20 1996-02-16    3    5  0     0 1996-02-15  1.856686   \n",
       "24479          20 1996-02-16   21    0  0     0 1996-02-15  1.489967   \n",
       "24481          20 1996-02-16   30    4  0     0 1996-02-15  2.481544   \n",
       "24485          20 1996-02-16   20    1  0     0 1996-02-15  1.251116   \n",
       "\n",
       "          OddsA  H  ...   HFTM   HFTA   HORB   HDRB    HRB   HAST  HSTL  HBLK  \\\n",
       "24473  3.195158  1  ...  16.00  22.12  11.64  31.52  43.16  18.36  6.44  4.56   \n",
       "24478  1.882726  1  ...  23.00  29.64   9.48  28.80  38.28  21.64  7.08  5.52   \n",
       "24479  2.576553  1  ...  17.96  26.56  13.16  30.80  43.96  21.56  6.96  5.44   \n",
       "24481  1.520993  1  ...  21.20  30.56  11.88  29.64  41.52  18.32  7.24  4.56   \n",
       "24485  4.039071  1  ...  20.68  25.16  11.68  31.92  43.60  21.16  6.96  5.44   \n",
       "\n",
       "        HTOV    HPF  \n",
       "24473  13.44  19.60  \n",
       "24478  15.88  22.84  \n",
       "24479  14.56  21.32  \n",
       "24481  17.44  22.92  \n",
       "24485  13.96  21.80  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolling_n = 25\n",
    "\n",
    "\n",
    "df_lastnH = df.groupby([\"Season\", \"HID\"]).rolling(rolling_n, closed=\"left\")[columnsH].mean().reset_index().dropna().set_index(\"level_2\").rename_axis(None).drop(columns=[\"HID\", \"Season\"])\n",
    "df_lastnA = df.groupby([\"Season\", \"AID\"]).rolling(rolling_n, closed=\"left\")[columnsA].mean().reset_index().dropna().set_index(\"level_2\").rename_axis(None).drop(columns=\"AID\")\n",
    "\n",
    "df_ml3 = pd.merge(df[meta_columns], df_lastnA, left_index=True, right_index=True)\n",
    "df_ml3 = pd.merge(df_ml3, df_lastnH, left_index=True, right_index=True)\n",
    "df_ml3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H ~ HFGM + HFGA + HFG3M + HFG3A + HFTM + HFTA + HORB + HDRB + HAST + HSTL + HBLK + HTOV + AFGM + AFGA + AFG3M + AFG3A + AFTM + AFTA + AORB + ADRB + AAST + ASTL + ABLK + ATOV\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.587208\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>H</td>        <th>  No. Observations:  </th>  <td>  2149</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  2124</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    24</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 05 Nov 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.1188</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>12:26:15</td>     <th>  Log-Likelihood:    </th> <td> -1261.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -1432.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.191e-57</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -1.6252</td> <td>    2.607</td> <td>   -0.623</td> <td> 0.533</td> <td>   -6.735</td> <td>    3.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFGM</th>      <td>    0.0880</td> <td>    0.047</td> <td>    1.877</td> <td> 0.061</td> <td>   -0.004</td> <td>    0.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFGA</th>      <td>   -0.2291</td> <td>    0.032</td> <td>   -7.118</td> <td> 0.000</td> <td>   -0.292</td> <td>   -0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFG3M</th>     <td>    0.2601</td> <td>    0.133</td> <td>    1.954</td> <td> 0.051</td> <td>   -0.001</td> <td>    0.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFG3A</th>     <td>   -0.0167</td> <td>    0.056</td> <td>   -0.299</td> <td> 0.765</td> <td>   -0.126</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFTM</th>      <td>    0.1738</td> <td>    0.068</td> <td>    2.560</td> <td> 0.010</td> <td>    0.041</td> <td>    0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HFTA</th>      <td>   -0.1672</td> <td>    0.058</td> <td>   -2.888</td> <td> 0.004</td> <td>   -0.281</td> <td>   -0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HORB</th>      <td>    0.3165</td> <td>    0.053</td> <td>    5.955</td> <td> 0.000</td> <td>    0.212</td> <td>    0.421</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HDRB</th>      <td>    0.2210</td> <td>    0.039</td> <td>    5.686</td> <td> 0.000</td> <td>    0.145</td> <td>    0.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HAST</th>      <td>    0.0947</td> <td>    0.028</td> <td>    3.369</td> <td> 0.001</td> <td>    0.040</td> <td>    0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HSTL</th>      <td>    0.3179</td> <td>    0.060</td> <td>    5.324</td> <td> 0.000</td> <td>    0.201</td> <td>    0.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HBLK</th>      <td>    0.1919</td> <td>    0.052</td> <td>    3.724</td> <td> 0.000</td> <td>    0.091</td> <td>    0.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HTOV</th>      <td>   -0.1979</td> <td>    0.045</td> <td>   -4.439</td> <td> 0.000</td> <td>   -0.285</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFGM</th>      <td>   -0.1593</td> <td>    0.056</td> <td>   -2.826</td> <td> 0.005</td> <td>   -0.270</td> <td>   -0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFGA</th>      <td>    0.2233</td> <td>    0.035</td> <td>    6.337</td> <td> 0.000</td> <td>    0.154</td> <td>    0.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFG3M</th>     <td>   -0.0781</td> <td>    0.122</td> <td>   -0.641</td> <td> 0.521</td> <td>   -0.317</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFG3A</th>     <td>   -0.0359</td> <td>    0.051</td> <td>   -0.701</td> <td> 0.483</td> <td>   -0.136</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFTM</th>      <td>   -0.0623</td> <td>    0.068</td> <td>   -0.920</td> <td> 0.358</td> <td>   -0.195</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AFTA</th>      <td>    0.0681</td> <td>    0.054</td> <td>    1.265</td> <td> 0.206</td> <td>   -0.037</td> <td>    0.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AORB</th>      <td>   -0.2311</td> <td>    0.058</td> <td>   -4.010</td> <td> 0.000</td> <td>   -0.344</td> <td>   -0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ADRB</th>      <td>   -0.1578</td> <td>    0.037</td> <td>   -4.214</td> <td> 0.000</td> <td>   -0.231</td> <td>   -0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AAST</th>      <td>   -0.0265</td> <td>    0.033</td> <td>   -0.802</td> <td> 0.423</td> <td>   -0.091</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ASTL</th>      <td>   -0.3362</td> <td>    0.070</td> <td>   -4.820</td> <td> 0.000</td> <td>   -0.473</td> <td>   -0.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ABLK</th>      <td>   -0.0627</td> <td>    0.071</td> <td>   -0.880</td> <td> 0.379</td> <td>   -0.202</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ATOV</th>      <td>    0.1911</td> <td>    0.039</td> <td>    4.915</td> <td> 0.000</td> <td>    0.115</td> <td>    0.267</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &        H         & \\textbf{  No. Observations:  } &     2149    \\\\\n",
       "\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &     2124    \\\\\n",
       "\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &       24    \\\\\n",
       "\\textbf{Date:}            & Tue, 05 Nov 2024 & \\textbf{  Pseudo R-squ.:     } &   0.1188    \\\\\n",
       "\\textbf{Time:}            &     12:26:15     & \\textbf{  Log-Likelihood:    } &   -1261.9   \\\\\n",
       "\\textbf{converged:}       &       True       & \\textbf{  LL-Null:           } &   -1432.0   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } & 1.191e-57   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      -1.6252  &        2.607     &    -0.623  &         0.533        &       -6.735    &        3.484     \\\\\n",
       "\\textbf{HFGM}      &       0.0880  &        0.047     &     1.877  &         0.061        &       -0.004    &        0.180     \\\\\n",
       "\\textbf{HFGA}      &      -0.2291  &        0.032     &    -7.118  &         0.000        &       -0.292    &       -0.166     \\\\\n",
       "\\textbf{HFG3M}     &       0.2601  &        0.133     &     1.954  &         0.051        &       -0.001    &        0.521     \\\\\n",
       "\\textbf{HFG3A}     &      -0.0167  &        0.056     &    -0.299  &         0.765        &       -0.126    &        0.093     \\\\\n",
       "\\textbf{HFTM}      &       0.1738  &        0.068     &     2.560  &         0.010        &        0.041    &        0.307     \\\\\n",
       "\\textbf{HFTA}      &      -0.1672  &        0.058     &    -2.888  &         0.004        &       -0.281    &       -0.054     \\\\\n",
       "\\textbf{HORB}      &       0.3165  &        0.053     &     5.955  &         0.000        &        0.212    &        0.421     \\\\\n",
       "\\textbf{HDRB}      &       0.2210  &        0.039     &     5.686  &         0.000        &        0.145    &        0.297     \\\\\n",
       "\\textbf{HAST}      &       0.0947  &        0.028     &     3.369  &         0.001        &        0.040    &        0.150     \\\\\n",
       "\\textbf{HSTL}      &       0.3179  &        0.060     &     5.324  &         0.000        &        0.201    &        0.435     \\\\\n",
       "\\textbf{HBLK}      &       0.1919  &        0.052     &     3.724  &         0.000        &        0.091    &        0.293     \\\\\n",
       "\\textbf{HTOV}      &      -0.1979  &        0.045     &    -4.439  &         0.000        &       -0.285    &       -0.111     \\\\\n",
       "\\textbf{AFGM}      &      -0.1593  &        0.056     &    -2.826  &         0.005        &       -0.270    &       -0.049     \\\\\n",
       "\\textbf{AFGA}      &       0.2233  &        0.035     &     6.337  &         0.000        &        0.154    &        0.292     \\\\\n",
       "\\textbf{AFG3M}     &      -0.0781  &        0.122     &    -0.641  &         0.521        &       -0.317    &        0.161     \\\\\n",
       "\\textbf{AFG3A}     &      -0.0359  &        0.051     &    -0.701  &         0.483        &       -0.136    &        0.065     \\\\\n",
       "\\textbf{AFTM}      &      -0.0623  &        0.068     &    -0.920  &         0.358        &       -0.195    &        0.071     \\\\\n",
       "\\textbf{AFTA}      &       0.0681  &        0.054     &     1.265  &         0.206        &       -0.037    &        0.174     \\\\\n",
       "\\textbf{AORB}      &      -0.2311  &        0.058     &    -4.010  &         0.000        &       -0.344    &       -0.118     \\\\\n",
       "\\textbf{ADRB}      &      -0.1578  &        0.037     &    -4.214  &         0.000        &       -0.231    &       -0.084     \\\\\n",
       "\\textbf{AAST}      &      -0.0265  &        0.033     &    -0.802  &         0.423        &       -0.091    &        0.038     \\\\\n",
       "\\textbf{ASTL}      &      -0.3362  &        0.070     &    -4.820  &         0.000        &       -0.473    &       -0.199     \\\\\n",
       "\\textbf{ABLK}      &      -0.0627  &        0.071     &    -0.880  &         0.379        &       -0.202    &        0.077     \\\\\n",
       "\\textbf{ATOV}      &       0.1911  &        0.039     &     4.915  &         0.000        &        0.115    &        0.267     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      H   No. Observations:                 2149\n",
       "Model:                          Logit   Df Residuals:                     2124\n",
       "Method:                           MLE   Df Model:                           24\n",
       "Date:                Tue, 05 Nov 2024   Pseudo R-squ.:                  0.1188\n",
       "Time:                        12:26:15   Log-Likelihood:                -1261.9\n",
       "converged:                       True   LL-Null:                       -1432.0\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.191e-57\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -1.6252      2.607     -0.623      0.533      -6.735       3.484\n",
       "HFGM           0.0880      0.047      1.877      0.061      -0.004       0.180\n",
       "HFGA          -0.2291      0.032     -7.118      0.000      -0.292      -0.166\n",
       "HFG3M          0.2601      0.133      1.954      0.051      -0.001       0.521\n",
       "HFG3A         -0.0167      0.056     -0.299      0.765      -0.126       0.093\n",
       "HFTM           0.1738      0.068      2.560      0.010       0.041       0.307\n",
       "HFTA          -0.1672      0.058     -2.888      0.004      -0.281      -0.054\n",
       "HORB           0.3165      0.053      5.955      0.000       0.212       0.421\n",
       "HDRB           0.2210      0.039      5.686      0.000       0.145       0.297\n",
       "HAST           0.0947      0.028      3.369      0.001       0.040       0.150\n",
       "HSTL           0.3179      0.060      5.324      0.000       0.201       0.435\n",
       "HBLK           0.1919      0.052      3.724      0.000       0.091       0.293\n",
       "HTOV          -0.1979      0.045     -4.439      0.000      -0.285      -0.111\n",
       "AFGM          -0.1593      0.056     -2.826      0.005      -0.270      -0.049\n",
       "AFGA           0.2233      0.035      6.337      0.000       0.154       0.292\n",
       "AFG3M         -0.0781      0.122     -0.641      0.521      -0.317       0.161\n",
       "AFG3A         -0.0359      0.051     -0.701      0.483      -0.136       0.065\n",
       "AFTM          -0.0623      0.068     -0.920      0.358      -0.195       0.071\n",
       "AFTA           0.0681      0.054      1.265      0.206      -0.037       0.174\n",
       "AORB          -0.2311      0.058     -4.010      0.000      -0.344      -0.118\n",
       "ADRB          -0.1578      0.037     -4.214      0.000      -0.231      -0.084\n",
       "AAST          -0.0265      0.033     -0.802      0.423      -0.091       0.038\n",
       "ASTL          -0.3362      0.070     -4.820      0.000      -0.473      -0.199\n",
       "ABLK          -0.0627      0.071     -0.880      0.379      -0.202       0.077\n",
       "ATOV           0.1911      0.039      4.915      0.000       0.115       0.267\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    \"HFGM\", \"HFGA\", \"HFG3M\", \"HFG3A\", \"HFTM\", \"HFTA\", \"HORB\", \"HDRB\", \"HAST\", \"HSTL\", \"HBLK\", \"HTOV\",\n",
    "    \"AFGM\", \"AFGA\", \"AFG3M\", \"AFG3A\", \"AFTM\", \"AFTA\", \"AORB\", \"ADRB\", \"AAST\", \"ASTL\", \"ABLK\", \"ATOV\",\n",
    "]\n",
    "# features = [\n",
    "#     \"HFGM\", \"HFGA\", \"HFG3M\", \"HFTM\", \"HFTA\", \"HORB\", \"HDRB\", \"HAST\", \"HSTL\", \"HTOV\",\n",
    "#     \"AFGM\", \"AFGA\", \"AFG3M\", \"AFTM\", \"AFTA\", \"AORB\", \"ADRB\", \"AAST\", \"ASTL\", \"ATOV\",\n",
    "# ]\n",
    "\n",
    "formula = \"H ~ \" + \" + \".join(features)\n",
    "print(formula)\n",
    "\n",
    "model = smf.logit(formula=formula, data=df_ml3)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyCaret AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_return(data, predictions):\n",
    "\n",
    "    r = 0\n",
    "    rs= []\n",
    "    for p, (_, row) in zip(predictions, data.iterrows()):\n",
    "        r -= 1\n",
    "        if p and row[\"H\"]:\n",
    "            r += row[\"OddsH\"]\n",
    "        \n",
    "        if not p and row[\"A\"]:\n",
    "            r += row[\"OddsA\"]\n",
    "\n",
    "        rs.append(r)\n",
    "\n",
    "    return r, rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d4e7c_row9_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d4e7c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d4e7c_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_d4e7c_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d4e7c_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_d4e7c_row0_col1\" class=\"data row0 col1\" >6567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d4e7c_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_d4e7c_row1_col1\" class=\"data row1 col1\" >H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d4e7c_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_d4e7c_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d4e7c_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_d4e7c_row3_col1\" class=\"data row3 col1\" >(2149, 43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d4e7c_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_d4e7c_row4_col1\" class=\"data row4 col1\" >(2149, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d4e7c_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_d4e7c_row5_col1\" class=\"data row5 col1\" >(1504, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d4e7c_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_d4e7c_row6_col1\" class=\"data row6 col1\" >(645, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d4e7c_row7_col0\" class=\"data row7 col0\" >Ignore features</td>\n",
       "      <td id=\"T_d4e7c_row7_col1\" class=\"data row7 col1\" >11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_d4e7c_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_d4e7c_row8_col1\" class=\"data row8 col1\" >31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_d4e7c_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_d4e7c_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_d4e7c_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_d4e7c_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_d4e7c_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_d4e7c_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_d4e7c_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_d4e7c_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_d4e7c_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_d4e7c_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_d4e7c_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_d4e7c_row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_d4e7c_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_d4e7c_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_d4e7c_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_d4e7c_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_d4e7c_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_d4e7c_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_d4e7c_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_d4e7c_row18_col1\" class=\"data row18 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e7c_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_d4e7c_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_d4e7c_row19_col1\" class=\"data row19 col1\" >2fc1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe0a57ef590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3c374 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3c374_row0_col0, #T_3c374_row0_col2, #T_3c374_row0_col3, #T_3c374_row0_col4, #T_3c374_row0_col5, #T_3c374_row1_col0, #T_3c374_row1_col1, #T_3c374_row1_col3, #T_3c374_row1_col4, #T_3c374_row1_col5, #T_3c374_row1_col6, #T_3c374_row1_col7, #T_3c374_row2_col0, #T_3c374_row2_col1, #T_3c374_row2_col3, #T_3c374_row2_col4, #T_3c374_row2_col5, #T_3c374_row2_col6, #T_3c374_row2_col7, #T_3c374_row3_col0, #T_3c374_row3_col1, #T_3c374_row3_col2, #T_3c374_row3_col3, #T_3c374_row3_col4, #T_3c374_row3_col5, #T_3c374_row3_col6, #T_3c374_row3_col7, #T_3c374_row4_col0, #T_3c374_row4_col1, #T_3c374_row4_col2, #T_3c374_row4_col3, #T_3c374_row4_col4, #T_3c374_row4_col5, #T_3c374_row4_col6, #T_3c374_row4_col7, #T_3c374_row5_col0, #T_3c374_row5_col1, #T_3c374_row5_col2, #T_3c374_row5_col3, #T_3c374_row5_col4, #T_3c374_row5_col5, #T_3c374_row5_col6, #T_3c374_row5_col7, #T_3c374_row6_col0, #T_3c374_row6_col1, #T_3c374_row6_col2, #T_3c374_row6_col3, #T_3c374_row6_col4, #T_3c374_row6_col5, #T_3c374_row6_col6, #T_3c374_row6_col7, #T_3c374_row7_col0, #T_3c374_row7_col1, #T_3c374_row7_col2, #T_3c374_row7_col3, #T_3c374_row7_col4, #T_3c374_row7_col5, #T_3c374_row7_col6, #T_3c374_row7_col7, #T_3c374_row8_col0, #T_3c374_row8_col1, #T_3c374_row8_col2, #T_3c374_row8_col3, #T_3c374_row8_col4, #T_3c374_row8_col5, #T_3c374_row8_col6, #T_3c374_row8_col7, #T_3c374_row9_col0, #T_3c374_row9_col1, #T_3c374_row9_col2, #T_3c374_row9_col3, #T_3c374_row9_col4, #T_3c374_row9_col5, #T_3c374_row9_col6, #T_3c374_row9_col7, #T_3c374_row10_col0, #T_3c374_row10_col1, #T_3c374_row10_col2, #T_3c374_row10_col4, #T_3c374_row10_col6, #T_3c374_row10_col7, #T_3c374_row11_col0, #T_3c374_row11_col1, #T_3c374_row11_col2, #T_3c374_row11_col3, #T_3c374_row11_col4, #T_3c374_row11_col5, #T_3c374_row11_col6, #T_3c374_row11_col7, #T_3c374_row12_col0, #T_3c374_row12_col1, #T_3c374_row12_col2, #T_3c374_row12_col3, #T_3c374_row12_col4, #T_3c374_row12_col5, #T_3c374_row12_col6, #T_3c374_row12_col7, #T_3c374_row13_col0, #T_3c374_row13_col1, #T_3c374_row13_col2, #T_3c374_row13_col3, #T_3c374_row13_col4, #T_3c374_row13_col5, #T_3c374_row13_col6, #T_3c374_row13_col7, #T_3c374_row14_col0, #T_3c374_row14_col1, #T_3c374_row14_col2, #T_3c374_row14_col3, #T_3c374_row14_col5, #T_3c374_row14_col6, #T_3c374_row14_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_3c374_row0_col1, #T_3c374_row0_col6, #T_3c374_row0_col7, #T_3c374_row1_col2, #T_3c374_row2_col2, #T_3c374_row10_col3, #T_3c374_row10_col5, #T_3c374_row14_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_3c374_row0_col8, #T_3c374_row1_col8, #T_3c374_row2_col8, #T_3c374_row3_col8, #T_3c374_row4_col8, #T_3c374_row5_col8, #T_3c374_row6_col8, #T_3c374_row7_col8, #T_3c374_row8_col8, #T_3c374_row9_col8, #T_3c374_row10_col8, #T_3c374_row12_col8, #T_3c374_row13_col8, #T_3c374_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_3c374_row11_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3c374\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3c374_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_3c374_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_3c374_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_3c374_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_3c374_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_3c374_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_3c374_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_3c374_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_3c374_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3c374_level0_row0\" class=\"row_heading level0 row0\" >lr</th>\n",
       "      <td id=\"T_3c374_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_3c374_row0_col1\" class=\"data row0 col1\" >0.6796</td>\n",
       "      <td id=\"T_3c374_row0_col2\" class=\"data row0 col2\" >0.7117</td>\n",
       "      <td id=\"T_3c374_row0_col3\" class=\"data row0 col3\" >0.8142</td>\n",
       "      <td id=\"T_3c374_row0_col4\" class=\"data row0 col4\" >0.7084</td>\n",
       "      <td id=\"T_3c374_row0_col5\" class=\"data row0 col5\" >0.7568</td>\n",
       "      <td id=\"T_3c374_row0_col6\" class=\"data row0 col6\" >0.2923</td>\n",
       "      <td id=\"T_3c374_row0_col7\" class=\"data row0 col7\" >0.3005</td>\n",
       "      <td id=\"T_3c374_row0_col8\" class=\"data row0 col8\" >0.1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c374_level0_row1\" class=\"row_heading level0 row1\" >lda</th>\n",
       "      <td id=\"T_3c374_row1_col0\" class=\"data row1 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_3c374_row1_col1\" class=\"data row1 col1\" >0.6789</td>\n",
       "      <td id=\"T_3c374_row1_col2\" class=\"data row1 col2\" >0.7119</td>\n",
       "      <td id=\"T_3c374_row1_col3\" class=\"data row1 col3\" >0.8163</td>\n",
       "      <td id=\"T_3c374_row1_col4\" class=\"data row1 col4\" >0.7070</td>\n",
       "      <td id=\"T_3c374_row1_col5\" class=\"data row1 col5\" >0.7569</td>\n",
       "      <td id=\"T_3c374_row1_col6\" class=\"data row1 col6\" >0.2897</td>\n",
       "      <td id=\"T_3c374_row1_col7\" class=\"data row1 col7\" >0.2984</td>\n",
       "      <td id=\"T_3c374_row1_col8\" class=\"data row1 col8\" >0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c374_level0_row2\" class=\"row_heading level0 row2\" >ridge</th>\n",
       "      <td id=\"T_3c374_row2_col0\" class=\"data row2 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_3c374_row2_col1\" class=\"data row2 col1\" >0.6783</td>\n",
       "      <td id=\"T_3c374_row2_col2\" class=\"data row2 col2\" >0.7119</td>\n",
       "      <td id=\"T_3c374_row2_col3\" class=\"data row2 col3\" >0.8196</td>\n",
       "      <td id=\"T_3c374_row2_col4\" class=\"data row2 col4\" >0.7054</td>\n",
       "      <td id=\"T_3c374_row2_col5\" class=\"data row2 col5\" >0.7574</td>\n",
       "      <td id=\"T_3c374_row2_col6\" class=\"data row2 col6\" >0.2862</td>\n",
       "      <td id=\"T_3c374_row2_col7\" class=\"data row2 col7\" >0.2953</td>\n",
       "      <td id=\"T_3c374_row2_col8\" class=\"data row2 col8\" >0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c374_level0_row3\" class=\"row_heading level0 row3\" >rf</th>\n",
       "      <td id=\"T_3c374_row3_col0\" class=\"data row3 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_3c374_row3_col1\" class=\"data row3 col1\" >0.6529</td>\n",
       "      <td id=\"T_3c374_row3_col2\" class=\"data row3 col2\" >0.6634</td>\n",
       "      <td id=\"T_3c374_row3_col3\" class=\"data row3 col3\" >0.8174</td>\n",
       "      <td id=\"T_3c374_row3_col4\" class=\"data row3 col4\" >0.6818</td>\n",
       "      <td id=\"T_3c374_row3_col5\" class=\"data row3 col5\" >0.7431</td>\n",
       "      <td id=\"T_3c374_row3_col6\" class=\"data row3 col6\" >0.2209</td>\n",
       "      <td id=\"T_3c374_row3_col7\" class=\"data row3 col7\" >0.2309</td>\n",
       "      <td id=\"T_3c374_row3_col8\" class=\"data row3 col8\" >0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c374_level0_row4\" class=\"row_heading level0 row4\" >gbc</th>\n",
       "      <td id=\"T_3c374_row4_col0\" class=\"data row4 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_3c374_row4_col1\" class=\"data row4 col1\" >0.6489</td>\n",
       "      <td id=\"T_3c374_row4_col2\" class=\"data row4 col2\" >0.6789</td>\n",
       "      <td id=\"T_3c374_row4_col3\" class=\"data row4 col3\" >0.8011</td>\n",
       "      <td id=\"T_3c374_row4_col4\" class=\"data row4 col4\" >0.6833</td>\n",
       "      <td id=\"T_3c374_row4_col5\" class=\"data row4 col5\" >0.7372</td>\n",
       "      <td id=\"T_3c374_row4_col6\" class=\"data row4 col6\" >0.2180</td>\n",
       "      <td id=\"T_3c374_row4_col7\" class=\"data row4 col7\" >0.2249</td>\n",
       "      <td id=\"T_3c374_row4_col8\" class=\"data row4 col8\" >0.0840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c374_level0_row5\" class=\"row_heading level0 row5\" >et</th>\n",
       "      <td id=\"T_3c374_row5_col0\" class=\"data row5 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_3c374_row5_col1\" class=\"data row5 col1\" >0.6470</td>\n",
       "      <td id=\"T_3c374_row5_col2\" class=\"data row5 col2\" >0.6466</td>\n",
       "      <td id=\"T_3c374_row5_col3\" class=\"data row5 col3\" >0.8065</td>\n",
       "      <td id=\"T_3c374_row5_col4\" class=\"data row5 col4\" >0.6797</td>\n",
       "      <td id=\"T_3c374_row5_col5\" class=\"data row5 col5\" >0.7375</td>\n",
       "      <td id=\"T_3c374_row5_col6\" class=\"data row5 col6\" >0.2101</td>\n",
       "      <td id=\"T_3c374_row5_col7\" class=\"data row5 col7\" >0.2179</td>\n",
       "      <td id=\"T_3c374_row5_col8\" class=\"data row5 col8\" >0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c374_level0_row6\" class=\"row_heading level0 row6\" >ada</th>\n",
       "      <td id=\"T_3c374_row6_col0\" class=\"data row6 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_3c374_row6_col1\" class=\"data row6 col1\" >0.6463</td>\n",
       "      <td id=\"T_3c374_row6_col2\" class=\"data row6 col2\" >0.6596</td>\n",
       "      <td id=\"T_3c374_row6_col3\" class=\"data row6 col3\" >0.7806</td>\n",
       "      <td id=\"T_3c374_row6_col4\" class=\"data row6 col4\" >0.6873</td>\n",
       "      <td id=\"T_3c374_row6_col5\" class=\"data row6 col5\" >0.7304</td>\n",
       "      <td id=\"T_3c374_row6_col6\" class=\"data row6 col6\" >0.2215</td>\n",
       "      <td id=\"T_3c374_row6_col7\" class=\"data row6 col7\" >0.2267</td>\n",
       "      <td id=\"T_3c374_row6_col8\" class=\"data row6 col8\" >0.0230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c374_level0_row7\" class=\"row_heading level0 row7\" >nb</th>\n",
       "      <td id=\"T_3c374_row7_col0\" class=\"data row7 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_3c374_row7_col1\" class=\"data row7 col1\" >0.6376</td>\n",
       "      <td id=\"T_3c374_row7_col2\" class=\"data row7 col2\" >0.6569</td>\n",
       "      <td id=\"T_3c374_row7_col3\" class=\"data row7 col3\" >0.7168</td>\n",
       "      <td id=\"T_3c374_row7_col4\" class=\"data row7 col4\" >0.7020</td>\n",
       "      <td id=\"T_3c374_row7_col5\" class=\"data row7 col5\" >0.7088</td>\n",
       "      <td id=\"T_3c374_row7_col6\" class=\"data row7 col6\" >0.2289</td>\n",
       "      <td id=\"T_3c374_row7_col7\" class=\"data row7 col7\" >0.2295</td>\n",
       "      <td id=\"T_3c374_row7_col8\" class=\"data row7 col8\" >0.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c374_level0_row8\" class=\"row_heading level0 row8\" >lightgbm</th>\n",
       "      <td id=\"T_3c374_row8_col0\" class=\"data row8 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_3c374_row8_col1\" class=\"data row8 col1\" >0.6376</td>\n",
       "      <td id=\"T_3c374_row8_col2\" class=\"data row8 col2\" >0.6529</td>\n",
       "      <td id=\"T_3c374_row8_col3\" class=\"data row8 col3\" >0.7708</td>\n",
       "      <td id=\"T_3c374_row8_col4\" class=\"data row8 col4\" >0.6820</td>\n",
       "      <td id=\"T_3c374_row8_col5\" class=\"data row8 col5\" >0.7229</td>\n",
       "      <td id=\"T_3c374_row8_col6\" class=\"data row8 col6\" >0.2037</td>\n",
       "      <td id=\"T_3c374_row8_col7\" class=\"data row8 col7\" >0.2084</td>\n",
       "      <td id=\"T_3c374_row8_col8\" class=\"data row8 col8\" >0.1590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c374_level0_row9\" class=\"row_heading level0 row9\" >xgboost</th>\n",
       "      <td id=\"T_3c374_row9_col0\" class=\"data row9 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_3c374_row9_col1\" class=\"data row9 col1\" >0.6350</td>\n",
       "      <td id=\"T_3c374_row9_col2\" class=\"data row9 col2\" >0.6477</td>\n",
       "      <td id=\"T_3c374_row9_col3\" class=\"data row9 col3\" >0.7569</td>\n",
       "      <td id=\"T_3c374_row9_col4\" class=\"data row9 col4\" >0.6842</td>\n",
       "      <td id=\"T_3c374_row9_col5\" class=\"data row9 col5\" >0.7178</td>\n",
       "      <td id=\"T_3c374_row9_col6\" class=\"data row9 col6\" >0.2037</td>\n",
       "      <td id=\"T_3c374_row9_col7\" class=\"data row9 col7\" >0.2071</td>\n",
       "      <td id=\"T_3c374_row9_col8\" class=\"data row9 col8\" >0.0290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c374_level0_row10\" class=\"row_heading level0 row10\" >dummy</th>\n",
       "      <td id=\"T_3c374_row10_col0\" class=\"data row10 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_3c374_row10_col1\" class=\"data row10 col1\" >0.6150</td>\n",
       "      <td id=\"T_3c374_row10_col2\" class=\"data row10 col2\" >0.5000</td>\n",
       "      <td id=\"T_3c374_row10_col3\" class=\"data row10 col3\" >1.0000</td>\n",
       "      <td id=\"T_3c374_row10_col4\" class=\"data row10 col4\" >0.6150</td>\n",
       "      <td id=\"T_3c374_row10_col5\" class=\"data row10 col5\" >0.7616</td>\n",
       "      <td id=\"T_3c374_row10_col6\" class=\"data row10 col6\" >0.0000</td>\n",
       "      <td id=\"T_3c374_row10_col7\" class=\"data row10 col7\" >0.0000</td>\n",
       "      <td id=\"T_3c374_row10_col8\" class=\"data row10 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c374_level0_row11\" class=\"row_heading level0 row11\" >qda</th>\n",
       "      <td id=\"T_3c374_row11_col0\" class=\"data row11 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_3c374_row11_col1\" class=\"data row11 col1\" >0.6137</td>\n",
       "      <td id=\"T_3c374_row11_col2\" class=\"data row11 col2\" >0.6401</td>\n",
       "      <td id=\"T_3c374_row11_col3\" class=\"data row11 col3\" >0.6564</td>\n",
       "      <td id=\"T_3c374_row11_col4\" class=\"data row11 col4\" >0.6977</td>\n",
       "      <td id=\"T_3c374_row11_col5\" class=\"data row11 col5\" >0.6738</td>\n",
       "      <td id=\"T_3c374_row11_col6\" class=\"data row11 col6\" >0.1996</td>\n",
       "      <td id=\"T_3c374_row11_col7\" class=\"data row11 col7\" >0.2016</td>\n",
       "      <td id=\"T_3c374_row11_col8\" class=\"data row11 col8\" >0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c374_level0_row12\" class=\"row_heading level0 row12\" >knn</th>\n",
       "      <td id=\"T_3c374_row12_col0\" class=\"data row12 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_3c374_row12_col1\" class=\"data row12 col1\" >0.6097</td>\n",
       "      <td id=\"T_3c374_row12_col2\" class=\"data row12 col2\" >0.5952</td>\n",
       "      <td id=\"T_3c374_row12_col3\" class=\"data row12 col3\" >0.7406</td>\n",
       "      <td id=\"T_3c374_row12_col4\" class=\"data row12 col4\" >0.6644</td>\n",
       "      <td id=\"T_3c374_row12_col5\" class=\"data row12 col5\" >0.6999</td>\n",
       "      <td id=\"T_3c374_row12_col6\" class=\"data row12 col6\" >0.1459</td>\n",
       "      <td id=\"T_3c374_row12_col7\" class=\"data row12 col7\" >0.1477</td>\n",
       "      <td id=\"T_3c374_row12_col8\" class=\"data row12 col8\" >0.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c374_level0_row13\" class=\"row_heading level0 row13\" >dt</th>\n",
       "      <td id=\"T_3c374_row13_col0\" class=\"data row13 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_3c374_row13_col1\" class=\"data row13 col1\" >0.5851</td>\n",
       "      <td id=\"T_3c374_row13_col2\" class=\"data row13 col2\" >0.5652</td>\n",
       "      <td id=\"T_3c374_row13_col3\" class=\"data row13 col3\" >0.6520</td>\n",
       "      <td id=\"T_3c374_row13_col4\" class=\"data row13 col4\" >0.6663</td>\n",
       "      <td id=\"T_3c374_row13_col5\" class=\"data row13 col5\" >0.6560</td>\n",
       "      <td id=\"T_3c374_row13_col6\" class=\"data row13 col6\" >0.1304</td>\n",
       "      <td id=\"T_3c374_row13_col7\" class=\"data row13 col7\" >0.1320</td>\n",
       "      <td id=\"T_3c374_row13_col8\" class=\"data row13 col8\" >0.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c374_level0_row14\" class=\"row_heading level0 row14\" >svm</th>\n",
       "      <td id=\"T_3c374_row14_col0\" class=\"data row14 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_3c374_row14_col1\" class=\"data row14 col1\" >0.5252</td>\n",
       "      <td id=\"T_3c374_row14_col2\" class=\"data row14 col2\" >0.7107</td>\n",
       "      <td id=\"T_3c374_row14_col3\" class=\"data row14 col3\" >0.3529</td>\n",
       "      <td id=\"T_3c374_row14_col4\" class=\"data row14 col4\" >0.7208</td>\n",
       "      <td id=\"T_3c374_row14_col5\" class=\"data row14 col5\" >0.4178</td>\n",
       "      <td id=\"T_3c374_row14_col6\" class=\"data row14 col6\" >0.1350</td>\n",
       "      <td id=\"T_3c374_row14_col7\" class=\"data row14 col7\" >0.1803</td>\n",
       "      <td id=\"T_3c374_row14_col8\" class=\"data row14 col8\" >0.0070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe0a1f34610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "py_cls = ClassificationExperiment()\n",
    "\n",
    "setup_params_cls = {\n",
    "    \"data\": df_ml3,\n",
    "    \"target\": \"H\",\n",
    "    \"ignore_features\": [\"Season\", \"Date\", \"HID\", \"AID\", \"N\", \"POFF\", \"Open\", \"OddsH\", \"OddsA\", \"A\", \"SortedTID\"],\n",
    "}\n",
    "\n",
    "py_cls.setup(**setup_params_cls)\n",
    "model = py_cls.compare_models(turbo=True, sort=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c3517_row9_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c3517\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c3517_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_c3517_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c3517_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_c3517_row0_col1\" class=\"data row0 col1\" >3629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c3517_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_c3517_row1_col1\" class=\"data row1 col1\" >H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c3517_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_c3517_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c3517_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_c3517_row3_col1\" class=\"data row3 col1\" >(1079, 43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c3517_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_c3517_row4_col1\" class=\"data row4 col1\" >(1079, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c3517_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_c3517_row5_col1\" class=\"data row5 col1\" >(539, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c3517_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_c3517_row6_col1\" class=\"data row6 col1\" >(540, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c3517_row7_col0\" class=\"data row7 col0\" >Ignore features</td>\n",
       "      <td id=\"T_c3517_row7_col1\" class=\"data row7 col1\" >11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c3517_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_c3517_row8_col1\" class=\"data row8 col1\" >31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c3517_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_c3517_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_c3517_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_c3517_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_c3517_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_c3517_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_c3517_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_c3517_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_c3517_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_c3517_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_c3517_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_c3517_row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_c3517_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_c3517_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_c3517_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_c3517_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_c3517_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_c3517_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_c3517_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_c3517_row18_col1\" class=\"data row18 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c3517_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_c3517_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_c3517_row19_col1\" class=\"data row19 col1\" >7b77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe0a24454d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2ab94 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2ab94_row0_col0, #T_2ab94_row0_col2, #T_2ab94_row0_col3, #T_2ab94_row0_col4, #T_2ab94_row0_col5, #T_2ab94_row0_col6, #T_2ab94_row0_col7, #T_2ab94_row1_col0, #T_2ab94_row1_col1, #T_2ab94_row1_col2, #T_2ab94_row1_col3, #T_2ab94_row1_col5, #T_2ab94_row2_col0, #T_2ab94_row2_col1, #T_2ab94_row2_col2, #T_2ab94_row2_col3, #T_2ab94_row2_col4, #T_2ab94_row2_col5, #T_2ab94_row2_col6, #T_2ab94_row2_col7, #T_2ab94_row3_col0, #T_2ab94_row3_col1, #T_2ab94_row3_col2, #T_2ab94_row3_col3, #T_2ab94_row3_col4, #T_2ab94_row3_col5, #T_2ab94_row3_col6, #T_2ab94_row3_col7, #T_2ab94_row4_col0, #T_2ab94_row4_col1, #T_2ab94_row4_col2, #T_2ab94_row4_col3, #T_2ab94_row4_col4, #T_2ab94_row4_col5, #T_2ab94_row4_col6, #T_2ab94_row4_col7, #T_2ab94_row5_col0, #T_2ab94_row5_col1, #T_2ab94_row5_col3, #T_2ab94_row5_col4, #T_2ab94_row5_col5, #T_2ab94_row5_col6, #T_2ab94_row5_col7, #T_2ab94_row6_col0, #T_2ab94_row6_col1, #T_2ab94_row6_col2, #T_2ab94_row6_col3, #T_2ab94_row6_col4, #T_2ab94_row6_col5, #T_2ab94_row6_col6, #T_2ab94_row6_col7, #T_2ab94_row7_col0, #T_2ab94_row7_col1, #T_2ab94_row7_col2, #T_2ab94_row7_col3, #T_2ab94_row7_col4, #T_2ab94_row7_col5, #T_2ab94_row7_col6, #T_2ab94_row7_col7, #T_2ab94_row8_col0, #T_2ab94_row8_col1, #T_2ab94_row8_col2, #T_2ab94_row8_col3, #T_2ab94_row8_col4, #T_2ab94_row8_col5, #T_2ab94_row8_col6, #T_2ab94_row8_col7, #T_2ab94_row9_col0, #T_2ab94_row9_col1, #T_2ab94_row9_col2, #T_2ab94_row9_col3, #T_2ab94_row9_col4, #T_2ab94_row9_col5, #T_2ab94_row9_col6, #T_2ab94_row9_col7, #T_2ab94_row10_col0, #T_2ab94_row10_col1, #T_2ab94_row10_col2, #T_2ab94_row10_col3, #T_2ab94_row10_col4, #T_2ab94_row10_col5, #T_2ab94_row10_col6, #T_2ab94_row10_col7, #T_2ab94_row11_col0, #T_2ab94_row11_col1, #T_2ab94_row11_col2, #T_2ab94_row11_col4, #T_2ab94_row11_col6, #T_2ab94_row11_col7, #T_2ab94_row12_col0, #T_2ab94_row12_col1, #T_2ab94_row12_col2, #T_2ab94_row12_col3, #T_2ab94_row12_col4, #T_2ab94_row12_col5, #T_2ab94_row12_col6, #T_2ab94_row12_col7, #T_2ab94_row13_col0, #T_2ab94_row13_col1, #T_2ab94_row13_col2, #T_2ab94_row13_col3, #T_2ab94_row13_col4, #T_2ab94_row13_col5, #T_2ab94_row13_col6, #T_2ab94_row13_col7, #T_2ab94_row14_col0, #T_2ab94_row14_col1, #T_2ab94_row14_col2, #T_2ab94_row14_col3, #T_2ab94_row14_col4, #T_2ab94_row14_col5, #T_2ab94_row14_col6, #T_2ab94_row14_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2ab94_row0_col1, #T_2ab94_row1_col4, #T_2ab94_row1_col6, #T_2ab94_row1_col7, #T_2ab94_row5_col2, #T_2ab94_row11_col3, #T_2ab94_row11_col5 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_2ab94_row0_col8, #T_2ab94_row1_col8, #T_2ab94_row2_col8, #T_2ab94_row4_col8, #T_2ab94_row5_col8, #T_2ab94_row6_col8, #T_2ab94_row7_col8, #T_2ab94_row8_col8, #T_2ab94_row9_col8, #T_2ab94_row10_col8, #T_2ab94_row13_col8, #T_2ab94_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_2ab94_row3_col8, #T_2ab94_row11_col8, #T_2ab94_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2ab94\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2ab94_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_2ab94_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_2ab94_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_2ab94_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_2ab94_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_2ab94_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_2ab94_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_2ab94_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_2ab94_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2ab94_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
       "      <td id=\"T_2ab94_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_2ab94_row0_col1\" class=\"data row0 col1\" >0.6419</td>\n",
       "      <td id=\"T_2ab94_row0_col2\" class=\"data row0 col2\" >0.6375</td>\n",
       "      <td id=\"T_2ab94_row0_col3\" class=\"data row0 col3\" >0.7766</td>\n",
       "      <td id=\"T_2ab94_row0_col4\" class=\"data row0 col4\" >0.6737</td>\n",
       "      <td id=\"T_2ab94_row0_col5\" class=\"data row0 col5\" >0.7195</td>\n",
       "      <td id=\"T_2ab94_row0_col6\" class=\"data row0 col6\" >0.2296</td>\n",
       "      <td id=\"T_2ab94_row0_col7\" class=\"data row0 col7\" >0.2347</td>\n",
       "      <td id=\"T_2ab94_row0_col8\" class=\"data row0 col8\" >0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ab94_level0_row1\" class=\"row_heading level0 row1\" >ada</th>\n",
       "      <td id=\"T_2ab94_row1_col0\" class=\"data row1 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_2ab94_row1_col1\" class=\"data row1 col1\" >0.6401</td>\n",
       "      <td id=\"T_2ab94_row1_col2\" class=\"data row1 col2\" >0.6458</td>\n",
       "      <td id=\"T_2ab94_row1_col3\" class=\"data row1 col3\" >0.7418</td>\n",
       "      <td id=\"T_2ab94_row1_col4\" class=\"data row1 col4\" >0.6818</td>\n",
       "      <td id=\"T_2ab94_row1_col5\" class=\"data row1 col5\" >0.7082</td>\n",
       "      <td id=\"T_2ab94_row1_col6\" class=\"data row1 col6\" >0.2385</td>\n",
       "      <td id=\"T_2ab94_row1_col7\" class=\"data row1 col7\" >0.2434</td>\n",
       "      <td id=\"T_2ab94_row1_col8\" class=\"data row1 col8\" >0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ab94_level0_row2\" class=\"row_heading level0 row2\" >ridge</th>\n",
       "      <td id=\"T_2ab94_row2_col0\" class=\"data row2 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_2ab94_row2_col1\" class=\"data row2 col1\" >0.6365</td>\n",
       "      <td id=\"T_2ab94_row2_col2\" class=\"data row2 col2\" >0.6423</td>\n",
       "      <td id=\"T_2ab94_row2_col3\" class=\"data row2 col3\" >0.7925</td>\n",
       "      <td id=\"T_2ab94_row2_col4\" class=\"data row2 col4\" >0.6594</td>\n",
       "      <td id=\"T_2ab94_row2_col5\" class=\"data row2 col5\" >0.7189</td>\n",
       "      <td id=\"T_2ab94_row2_col6\" class=\"data row2 col6\" >0.2139</td>\n",
       "      <td id=\"T_2ab94_row2_col7\" class=\"data row2 col7\" >0.2230</td>\n",
       "      <td id=\"T_2ab94_row2_col8\" class=\"data row2 col8\" >0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ab94_level0_row3\" class=\"row_heading level0 row3\" >lda</th>\n",
       "      <td id=\"T_2ab94_row3_col0\" class=\"data row3 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_2ab94_row3_col1\" class=\"data row3 col1\" >0.6365</td>\n",
       "      <td id=\"T_2ab94_row3_col2\" class=\"data row3 col2\" >0.6422</td>\n",
       "      <td id=\"T_2ab94_row3_col3\" class=\"data row3 col3\" >0.7894</td>\n",
       "      <td id=\"T_2ab94_row3_col4\" class=\"data row3 col4\" >0.6602</td>\n",
       "      <td id=\"T_2ab94_row3_col5\" class=\"data row3 col5\" >0.7178</td>\n",
       "      <td id=\"T_2ab94_row3_col6\" class=\"data row3 col6\" >0.2152</td>\n",
       "      <td id=\"T_2ab94_row3_col7\" class=\"data row3 col7\" >0.2244</td>\n",
       "      <td id=\"T_2ab94_row3_col8\" class=\"data row3 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ab94_level0_row4\" class=\"row_heading level0 row4\" >lr</th>\n",
       "      <td id=\"T_2ab94_row4_col0\" class=\"data row4 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_2ab94_row4_col1\" class=\"data row4 col1\" >0.6346</td>\n",
       "      <td id=\"T_2ab94_row4_col2\" class=\"data row4 col2\" >0.6436</td>\n",
       "      <td id=\"T_2ab94_row4_col3\" class=\"data row4 col3\" >0.7990</td>\n",
       "      <td id=\"T_2ab94_row4_col4\" class=\"data row4 col4\" >0.6562</td>\n",
       "      <td id=\"T_2ab94_row4_col5\" class=\"data row4 col5\" >0.7196</td>\n",
       "      <td id=\"T_2ab94_row4_col6\" class=\"data row4 col6\" >0.2070</td>\n",
       "      <td id=\"T_2ab94_row4_col7\" class=\"data row4 col7\" >0.2177</td>\n",
       "      <td id=\"T_2ab94_row4_col8\" class=\"data row4 col8\" >0.1450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ab94_level0_row5\" class=\"row_heading level0 row5\" >gbc</th>\n",
       "      <td id=\"T_2ab94_row5_col0\" class=\"data row5 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_2ab94_row5_col1\" class=\"data row5 col1\" >0.6310</td>\n",
       "      <td id=\"T_2ab94_row5_col2\" class=\"data row5 col2\" >0.6522</td>\n",
       "      <td id=\"T_2ab94_row5_col3\" class=\"data row5 col3\" >0.7482</td>\n",
       "      <td id=\"T_2ab94_row5_col4\" class=\"data row5 col4\" >0.6690</td>\n",
       "      <td id=\"T_2ab94_row5_col5\" class=\"data row5 col5\" >0.7047</td>\n",
       "      <td id=\"T_2ab94_row5_col6\" class=\"data row5 col6\" >0.2144</td>\n",
       "      <td id=\"T_2ab94_row5_col7\" class=\"data row5 col7\" >0.2185</td>\n",
       "      <td id=\"T_2ab94_row5_col8\" class=\"data row5 col8\" >0.0390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ab94_level0_row6\" class=\"row_heading level0 row6\" >rf</th>\n",
       "      <td id=\"T_2ab94_row6_col0\" class=\"data row6 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_2ab94_row6_col1\" class=\"data row6 col1\" >0.6179</td>\n",
       "      <td id=\"T_2ab94_row6_col2\" class=\"data row6 col2\" >0.6406</td>\n",
       "      <td id=\"T_2ab94_row6_col3\" class=\"data row6 col3\" >0.7546</td>\n",
       "      <td id=\"T_2ab94_row6_col4\" class=\"data row6 col4\" >0.6540</td>\n",
       "      <td id=\"T_2ab94_row6_col5\" class=\"data row6 col5\" >0.6997</td>\n",
       "      <td id=\"T_2ab94_row6_col6\" class=\"data row6 col6\" >0.1807</td>\n",
       "      <td id=\"T_2ab94_row6_col7\" class=\"data row6 col7\" >0.1845</td>\n",
       "      <td id=\"T_2ab94_row6_col8\" class=\"data row6 col8\" >0.0240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ab94_level0_row7\" class=\"row_heading level0 row7\" >qda</th>\n",
       "      <td id=\"T_2ab94_row7_col0\" class=\"data row7 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_2ab94_row7_col1\" class=\"data row7 col1\" >0.6161</td>\n",
       "      <td id=\"T_2ab94_row7_col2\" class=\"data row7 col2\" >0.6204</td>\n",
       "      <td id=\"T_2ab94_row7_col3\" class=\"data row7 col3\" >0.6829</td>\n",
       "      <td id=\"T_2ab94_row7_col4\" class=\"data row7 col4\" >0.6740</td>\n",
       "      <td id=\"T_2ab94_row7_col5\" class=\"data row7 col5\" >0.6736</td>\n",
       "      <td id=\"T_2ab94_row7_col6\" class=\"data row7 col6\" >0.2049</td>\n",
       "      <td id=\"T_2ab94_row7_col7\" class=\"data row7 col7\" >0.2093</td>\n",
       "      <td id=\"T_2ab94_row7_col8\" class=\"data row7 col8\" >0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ab94_level0_row8\" class=\"row_heading level0 row8\" >nb</th>\n",
       "      <td id=\"T_2ab94_row8_col0\" class=\"data row8 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_2ab94_row8_col1\" class=\"data row8 col1\" >0.6159</td>\n",
       "      <td id=\"T_2ab94_row8_col2\" class=\"data row8 col2\" >0.6346</td>\n",
       "      <td id=\"T_2ab94_row8_col3\" class=\"data row8 col3\" >0.6752</td>\n",
       "      <td id=\"T_2ab94_row8_col4\" class=\"data row8 col4\" >0.6751</td>\n",
       "      <td id=\"T_2ab94_row8_col5\" class=\"data row8 col5\" >0.6713</td>\n",
       "      <td id=\"T_2ab94_row8_col6\" class=\"data row8 col6\" >0.2060</td>\n",
       "      <td id=\"T_2ab94_row8_col7\" class=\"data row8 col7\" >0.2108</td>\n",
       "      <td id=\"T_2ab94_row8_col8\" class=\"data row8 col8\" >0.0710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ab94_level0_row9\" class=\"row_heading level0 row9\" >lightgbm</th>\n",
       "      <td id=\"T_2ab94_row9_col0\" class=\"data row9 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_2ab94_row9_col1\" class=\"data row9 col1\" >0.6049</td>\n",
       "      <td id=\"T_2ab94_row9_col2\" class=\"data row9 col2\" >0.6159</td>\n",
       "      <td id=\"T_2ab94_row9_col3\" class=\"data row9 col3\" >0.7173</td>\n",
       "      <td id=\"T_2ab94_row9_col4\" class=\"data row9 col4\" >0.6522</td>\n",
       "      <td id=\"T_2ab94_row9_col5\" class=\"data row9 col5\" >0.6816</td>\n",
       "      <td id=\"T_2ab94_row9_col6\" class=\"data row9 col6\" >0.1632</td>\n",
       "      <td id=\"T_2ab94_row9_col7\" class=\"data row9 col7\" >0.1652</td>\n",
       "      <td id=\"T_2ab94_row9_col8\" class=\"data row9 col8\" >0.0850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ab94_level0_row10\" class=\"row_heading level0 row10\" >xgboost</th>\n",
       "      <td id=\"T_2ab94_row10_col0\" class=\"data row10 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_2ab94_row10_col1\" class=\"data row10 col1\" >0.5995</td>\n",
       "      <td id=\"T_2ab94_row10_col2\" class=\"data row10 col2\" >0.6176</td>\n",
       "      <td id=\"T_2ab94_row10_col3\" class=\"data row10 col3\" >0.7014</td>\n",
       "      <td id=\"T_2ab94_row10_col4\" class=\"data row10 col4\" >0.6493</td>\n",
       "      <td id=\"T_2ab94_row10_col5\" class=\"data row10 col5\" >0.6731</td>\n",
       "      <td id=\"T_2ab94_row10_col6\" class=\"data row10 col6\" >0.1562</td>\n",
       "      <td id=\"T_2ab94_row10_col7\" class=\"data row10 col7\" >0.1578</td>\n",
       "      <td id=\"T_2ab94_row10_col8\" class=\"data row10 col8\" >0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ab94_level0_row11\" class=\"row_heading level0 row11\" >dummy</th>\n",
       "      <td id=\"T_2ab94_row11_col0\" class=\"data row11 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_2ab94_row11_col1\" class=\"data row11 col1\" >0.5900</td>\n",
       "      <td id=\"T_2ab94_row11_col2\" class=\"data row11 col2\" >0.5000</td>\n",
       "      <td id=\"T_2ab94_row11_col3\" class=\"data row11 col3\" >1.0000</td>\n",
       "      <td id=\"T_2ab94_row11_col4\" class=\"data row11 col4\" >0.5900</td>\n",
       "      <td id=\"T_2ab94_row11_col5\" class=\"data row11 col5\" >0.7421</td>\n",
       "      <td id=\"T_2ab94_row11_col6\" class=\"data row11 col6\" >0.0000</td>\n",
       "      <td id=\"T_2ab94_row11_col7\" class=\"data row11 col7\" >0.0000</td>\n",
       "      <td id=\"T_2ab94_row11_col8\" class=\"data row11 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ab94_level0_row12\" class=\"row_heading level0 row12\" >svm</th>\n",
       "      <td id=\"T_2ab94_row12_col0\" class=\"data row12 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_2ab94_row12_col1\" class=\"data row12 col1\" >0.5602</td>\n",
       "      <td id=\"T_2ab94_row12_col2\" class=\"data row12 col2\" >0.6393</td>\n",
       "      <td id=\"T_2ab94_row12_col3\" class=\"data row12 col3\" >0.6512</td>\n",
       "      <td id=\"T_2ab94_row12_col4\" class=\"data row12 col4\" >0.5924</td>\n",
       "      <td id=\"T_2ab94_row12_col5\" class=\"data row12 col5\" >0.5615</td>\n",
       "      <td id=\"T_2ab94_row12_col6\" class=\"data row12 col6\" >0.0698</td>\n",
       "      <td id=\"T_2ab94_row12_col7\" class=\"data row12 col7\" >0.0809</td>\n",
       "      <td id=\"T_2ab94_row12_col8\" class=\"data row12 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ab94_level0_row13\" class=\"row_heading level0 row13\" >dt</th>\n",
       "      <td id=\"T_2ab94_row13_col0\" class=\"data row13 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_2ab94_row13_col1\" class=\"data row13 col1\" >0.5530</td>\n",
       "      <td id=\"T_2ab94_row13_col2\" class=\"data row13 col2\" >0.5420</td>\n",
       "      <td id=\"T_2ab94_row13_col3\" class=\"data row13 col3\" >0.6031</td>\n",
       "      <td id=\"T_2ab94_row13_col4\" class=\"data row13 col4\" >0.6314</td>\n",
       "      <td id=\"T_2ab94_row13_col5\" class=\"data row13 col5\" >0.6149</td>\n",
       "      <td id=\"T_2ab94_row13_col6\" class=\"data row13 col6\" >0.0804</td>\n",
       "      <td id=\"T_2ab94_row13_col7\" class=\"data row13 col7\" >0.0818</td>\n",
       "      <td id=\"T_2ab94_row13_col8\" class=\"data row13 col8\" >0.0070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2ab94_level0_row14\" class=\"row_heading level0 row14\" >knn</th>\n",
       "      <td id=\"T_2ab94_row14_col0\" class=\"data row14 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_2ab94_row14_col1\" class=\"data row14 col1\" >0.5529</td>\n",
       "      <td id=\"T_2ab94_row14_col2\" class=\"data row14 col2\" >0.5701</td>\n",
       "      <td id=\"T_2ab94_row14_col3\" class=\"data row14 col3\" >0.6540</td>\n",
       "      <td id=\"T_2ab94_row14_col4\" class=\"data row14 col4\" >0.6157</td>\n",
       "      <td id=\"T_2ab94_row14_col5\" class=\"data row14 col5\" >0.6317</td>\n",
       "      <td id=\"T_2ab94_row14_col6\" class=\"data row14 col6\" >0.0606</td>\n",
       "      <td id=\"T_2ab94_row14_col7\" class=\"data row14 col7\" >0.0613</td>\n",
       "      <td id=\"T_2ab94_row14_col8\" class=\"data row14 col8\" >0.1190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe0a1e9ce90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d6aaf_row9_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d6aaf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d6aaf_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_d6aaf_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d6aaf_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_d6aaf_row0_col1\" class=\"data row0 col1\" >4494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d6aaf_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_d6aaf_row1_col1\" class=\"data row1 col1\" >H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d6aaf_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_d6aaf_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d6aaf_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_d6aaf_row3_col1\" class=\"data row3 col1\" >(1074, 43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d6aaf_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_d6aaf_row4_col1\" class=\"data row4 col1\" >(1074, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d6aaf_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_d6aaf_row5_col1\" class=\"data row5 col1\" >(540, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d6aaf_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_d6aaf_row6_col1\" class=\"data row6 col1\" >(534, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d6aaf_row7_col0\" class=\"data row7 col0\" >Ignore features</td>\n",
       "      <td id=\"T_d6aaf_row7_col1\" class=\"data row7 col1\" >11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_d6aaf_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_d6aaf_row8_col1\" class=\"data row8 col1\" >31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_d6aaf_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_d6aaf_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_d6aaf_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_d6aaf_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_d6aaf_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_d6aaf_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_d6aaf_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_d6aaf_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_d6aaf_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_d6aaf_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_d6aaf_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_d6aaf_row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_d6aaf_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_d6aaf_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_d6aaf_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_d6aaf_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_d6aaf_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_d6aaf_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_d6aaf_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_d6aaf_row18_col1\" class=\"data row18 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d6aaf_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_d6aaf_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_d6aaf_row19_col1\" class=\"data row19 col1\" >2875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe0bb47f810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8d71d th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8d71d_row0_col0, #T_8d71d_row0_col2, #T_8d71d_row0_col3, #T_8d71d_row0_col4, #T_8d71d_row0_col5, #T_8d71d_row1_col0, #T_8d71d_row1_col1, #T_8d71d_row1_col3, #T_8d71d_row1_col4, #T_8d71d_row1_col5, #T_8d71d_row1_col6, #T_8d71d_row1_col7, #T_8d71d_row2_col0, #T_8d71d_row2_col1, #T_8d71d_row2_col2, #T_8d71d_row2_col3, #T_8d71d_row2_col4, #T_8d71d_row2_col5, #T_8d71d_row2_col6, #T_8d71d_row2_col7, #T_8d71d_row3_col0, #T_8d71d_row3_col1, #T_8d71d_row3_col2, #T_8d71d_row3_col3, #T_8d71d_row3_col4, #T_8d71d_row3_col5, #T_8d71d_row3_col6, #T_8d71d_row3_col7, #T_8d71d_row4_col0, #T_8d71d_row4_col1, #T_8d71d_row4_col2, #T_8d71d_row4_col3, #T_8d71d_row4_col4, #T_8d71d_row4_col5, #T_8d71d_row4_col6, #T_8d71d_row4_col7, #T_8d71d_row5_col0, #T_8d71d_row5_col1, #T_8d71d_row5_col2, #T_8d71d_row5_col3, #T_8d71d_row5_col4, #T_8d71d_row5_col5, #T_8d71d_row5_col6, #T_8d71d_row5_col7, #T_8d71d_row6_col0, #T_8d71d_row6_col1, #T_8d71d_row6_col2, #T_8d71d_row6_col4, #T_8d71d_row6_col6, #T_8d71d_row6_col7, #T_8d71d_row7_col0, #T_8d71d_row7_col1, #T_8d71d_row7_col2, #T_8d71d_row7_col3, #T_8d71d_row7_col4, #T_8d71d_row7_col5, #T_8d71d_row7_col6, #T_8d71d_row7_col7, #T_8d71d_row8_col0, #T_8d71d_row8_col1, #T_8d71d_row8_col2, #T_8d71d_row8_col3, #T_8d71d_row8_col4, #T_8d71d_row8_col5, #T_8d71d_row8_col6, #T_8d71d_row8_col7, #T_8d71d_row9_col0, #T_8d71d_row9_col1, #T_8d71d_row9_col2, #T_8d71d_row9_col3, #T_8d71d_row9_col4, #T_8d71d_row9_col5, #T_8d71d_row9_col6, #T_8d71d_row9_col7, #T_8d71d_row10_col0, #T_8d71d_row10_col1, #T_8d71d_row10_col2, #T_8d71d_row10_col3, #T_8d71d_row10_col5, #T_8d71d_row10_col6, #T_8d71d_row10_col7, #T_8d71d_row11_col0, #T_8d71d_row11_col1, #T_8d71d_row11_col2, #T_8d71d_row11_col3, #T_8d71d_row11_col4, #T_8d71d_row11_col5, #T_8d71d_row11_col6, #T_8d71d_row11_col7, #T_8d71d_row12_col0, #T_8d71d_row12_col1, #T_8d71d_row12_col2, #T_8d71d_row12_col3, #T_8d71d_row12_col4, #T_8d71d_row12_col5, #T_8d71d_row12_col6, #T_8d71d_row12_col7, #T_8d71d_row13_col0, #T_8d71d_row13_col1, #T_8d71d_row13_col2, #T_8d71d_row13_col3, #T_8d71d_row13_col4, #T_8d71d_row13_col5, #T_8d71d_row13_col6, #T_8d71d_row13_col7, #T_8d71d_row14_col0, #T_8d71d_row14_col1, #T_8d71d_row14_col2, #T_8d71d_row14_col3, #T_8d71d_row14_col4, #T_8d71d_row14_col5, #T_8d71d_row14_col6, #T_8d71d_row14_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_8d71d_row0_col1, #T_8d71d_row0_col6, #T_8d71d_row0_col7, #T_8d71d_row1_col2, #T_8d71d_row6_col3, #T_8d71d_row6_col5, #T_8d71d_row10_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_8d71d_row0_col8, #T_8d71d_row2_col8, #T_8d71d_row6_col8, #T_8d71d_row9_col8, #T_8d71d_row10_col8, #T_8d71d_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_8d71d_row1_col8, #T_8d71d_row3_col8, #T_8d71d_row4_col8, #T_8d71d_row5_col8, #T_8d71d_row7_col8, #T_8d71d_row8_col8, #T_8d71d_row11_col8, #T_8d71d_row12_col8, #T_8d71d_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8d71d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8d71d_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_8d71d_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_8d71d_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_8d71d_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_8d71d_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_8d71d_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_8d71d_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_8d71d_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_8d71d_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8d71d_level0_row0\" class=\"row_heading level0 row0\" >ridge</th>\n",
       "      <td id=\"T_8d71d_row0_col0\" class=\"data row0 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_8d71d_row0_col1\" class=\"data row0 col1\" >0.6944</td>\n",
       "      <td id=\"T_8d71d_row0_col2\" class=\"data row0 col2\" >0.6984</td>\n",
       "      <td id=\"T_8d71d_row0_col3\" class=\"data row0 col3\" >0.8442</td>\n",
       "      <td id=\"T_8d71d_row0_col4\" class=\"data row0 col4\" >0.7270</td>\n",
       "      <td id=\"T_8d71d_row0_col5\" class=\"data row0 col5\" >0.7792</td>\n",
       "      <td id=\"T_8d71d_row0_col6\" class=\"data row0 col6\" >0.2853</td>\n",
       "      <td id=\"T_8d71d_row0_col7\" class=\"data row0 col7\" >0.2946</td>\n",
       "      <td id=\"T_8d71d_row0_col8\" class=\"data row0 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d71d_level0_row1\" class=\"row_heading level0 row1\" >lr</th>\n",
       "      <td id=\"T_8d71d_row1_col0\" class=\"data row1 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_8d71d_row1_col1\" class=\"data row1 col1\" >0.6907</td>\n",
       "      <td id=\"T_8d71d_row1_col2\" class=\"data row1 col2\" >0.7009</td>\n",
       "      <td id=\"T_8d71d_row1_col3\" class=\"data row1 col3\" >0.8385</td>\n",
       "      <td id=\"T_8d71d_row1_col4\" class=\"data row1 col4\" >0.7262</td>\n",
       "      <td id=\"T_8d71d_row1_col5\" class=\"data row1 col5\" >0.7761</td>\n",
       "      <td id=\"T_8d71d_row1_col6\" class=\"data row1 col6\" >0.2779</td>\n",
       "      <td id=\"T_8d71d_row1_col7\" class=\"data row1 col7\" >0.2867</td>\n",
       "      <td id=\"T_8d71d_row1_col8\" class=\"data row1 col8\" >0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d71d_level0_row2\" class=\"row_heading level0 row2\" >lda</th>\n",
       "      <td id=\"T_8d71d_row2_col0\" class=\"data row2 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_8d71d_row2_col1\" class=\"data row2 col1\" >0.6870</td>\n",
       "      <td id=\"T_8d71d_row2_col2\" class=\"data row2 col2\" >0.6984</td>\n",
       "      <td id=\"T_8d71d_row2_col3\" class=\"data row2 col3\" >0.8326</td>\n",
       "      <td id=\"T_8d71d_row2_col4\" class=\"data row2 col4\" >0.7240</td>\n",
       "      <td id=\"T_8d71d_row2_col5\" class=\"data row2 col5\" >0.7724</td>\n",
       "      <td id=\"T_8d71d_row2_col6\" class=\"data row2 col6\" >0.2720</td>\n",
       "      <td id=\"T_8d71d_row2_col7\" class=\"data row2 col7\" >0.2803</td>\n",
       "      <td id=\"T_8d71d_row2_col8\" class=\"data row2 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d71d_level0_row3\" class=\"row_heading level0 row3\" >rf</th>\n",
       "      <td id=\"T_8d71d_row3_col0\" class=\"data row3 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_8d71d_row3_col1\" class=\"data row3 col1\" >0.6630</td>\n",
       "      <td id=\"T_8d71d_row3_col2\" class=\"data row3 col2\" >0.6640</td>\n",
       "      <td id=\"T_8d71d_row3_col3\" class=\"data row3 col3\" >0.8358</td>\n",
       "      <td id=\"T_8d71d_row3_col4\" class=\"data row3 col4\" >0.6983</td>\n",
       "      <td id=\"T_8d71d_row3_col5\" class=\"data row3 col5\" >0.7592</td>\n",
       "      <td id=\"T_8d71d_row3_col6\" class=\"data row3 col6\" >0.2037</td>\n",
       "      <td id=\"T_8d71d_row3_col7\" class=\"data row3 col7\" >0.2176</td>\n",
       "      <td id=\"T_8d71d_row3_col8\" class=\"data row3 col8\" >0.0240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d71d_level0_row4\" class=\"row_heading level0 row4\" >ada</th>\n",
       "      <td id=\"T_8d71d_row4_col0\" class=\"data row4 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_8d71d_row4_col1\" class=\"data row4 col1\" >0.6500</td>\n",
       "      <td id=\"T_8d71d_row4_col2\" class=\"data row4 col2\" >0.6342</td>\n",
       "      <td id=\"T_8d71d_row4_col3\" class=\"data row4 col3\" >0.7666</td>\n",
       "      <td id=\"T_8d71d_row4_col4\" class=\"data row4 col4\" >0.7133</td>\n",
       "      <td id=\"T_8d71d_row4_col5\" class=\"data row4 col5\" >0.7369</td>\n",
       "      <td id=\"T_8d71d_row4_col6\" class=\"data row4 col6\" >0.2125</td>\n",
       "      <td id=\"T_8d71d_row4_col7\" class=\"data row4 col7\" >0.2153</td>\n",
       "      <td id=\"T_8d71d_row4_col8\" class=\"data row4 col8\" >0.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d71d_level0_row5\" class=\"row_heading level0 row5\" >et</th>\n",
       "      <td id=\"T_8d71d_row5_col0\" class=\"data row5 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_8d71d_row5_col1\" class=\"data row5 col1\" >0.6481</td>\n",
       "      <td id=\"T_8d71d_row5_col2\" class=\"data row5 col2\" >0.6455</td>\n",
       "      <td id=\"T_8d71d_row5_col3\" class=\"data row5 col3\" >0.8159</td>\n",
       "      <td id=\"T_8d71d_row5_col4\" class=\"data row5 col4\" >0.6898</td>\n",
       "      <td id=\"T_8d71d_row5_col5\" class=\"data row5 col5\" >0.7461</td>\n",
       "      <td id=\"T_8d71d_row5_col6\" class=\"data row5 col6\" >0.1780</td>\n",
       "      <td id=\"T_8d71d_row5_col7\" class=\"data row5 col7\" >0.1914</td>\n",
       "      <td id=\"T_8d71d_row5_col8\" class=\"data row5 col8\" >0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d71d_level0_row6\" class=\"row_heading level0 row6\" >dummy</th>\n",
       "      <td id=\"T_8d71d_row6_col0\" class=\"data row6 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_8d71d_row6_col1\" class=\"data row6 col1\" >0.6426</td>\n",
       "      <td id=\"T_8d71d_row6_col2\" class=\"data row6 col2\" >0.5000</td>\n",
       "      <td id=\"T_8d71d_row6_col3\" class=\"data row6 col3\" >1.0000</td>\n",
       "      <td id=\"T_8d71d_row6_col4\" class=\"data row6 col4\" >0.6426</td>\n",
       "      <td id=\"T_8d71d_row6_col5\" class=\"data row6 col5\" >0.7824</td>\n",
       "      <td id=\"T_8d71d_row6_col6\" class=\"data row6 col6\" >0.0000</td>\n",
       "      <td id=\"T_8d71d_row6_col7\" class=\"data row6 col7\" >0.0000</td>\n",
       "      <td id=\"T_8d71d_row6_col8\" class=\"data row6 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d71d_level0_row7\" class=\"row_heading level0 row7\" >xgboost</th>\n",
       "      <td id=\"T_8d71d_row7_col0\" class=\"data row7 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_8d71d_row7_col1\" class=\"data row7 col1\" >0.6370</td>\n",
       "      <td id=\"T_8d71d_row7_col2\" class=\"data row7 col2\" >0.6637</td>\n",
       "      <td id=\"T_8d71d_row7_col3\" class=\"data row7 col3\" >0.7727</td>\n",
       "      <td id=\"T_8d71d_row7_col4\" class=\"data row7 col4\" >0.6959</td>\n",
       "      <td id=\"T_8d71d_row7_col5\" class=\"data row7 col5\" >0.7315</td>\n",
       "      <td id=\"T_8d71d_row7_col6\" class=\"data row7 col6\" >0.1742</td>\n",
       "      <td id=\"T_8d71d_row7_col7\" class=\"data row7 col7\" >0.1785</td>\n",
       "      <td id=\"T_8d71d_row7_col8\" class=\"data row7 col8\" >0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d71d_level0_row8\" class=\"row_heading level0 row8\" >lightgbm</th>\n",
       "      <td id=\"T_8d71d_row8_col0\" class=\"data row8 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_8d71d_row8_col1\" class=\"data row8 col1\" >0.6333</td>\n",
       "      <td id=\"T_8d71d_row8_col2\" class=\"data row8 col2\" >0.6434</td>\n",
       "      <td id=\"T_8d71d_row8_col3\" class=\"data row8 col3\" >0.7787</td>\n",
       "      <td id=\"T_8d71d_row8_col4\" class=\"data row8 col4\" >0.6892</td>\n",
       "      <td id=\"T_8d71d_row8_col5\" class=\"data row8 col5\" >0.7305</td>\n",
       "      <td id=\"T_8d71d_row8_col6\" class=\"data row8 col6\" >0.1614</td>\n",
       "      <td id=\"T_8d71d_row8_col7\" class=\"data row8 col7\" >0.1683</td>\n",
       "      <td id=\"T_8d71d_row8_col8\" class=\"data row8 col8\" >0.0920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d71d_level0_row9\" class=\"row_heading level0 row9\" >nb</th>\n",
       "      <td id=\"T_8d71d_row9_col0\" class=\"data row9 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_8d71d_row9_col1\" class=\"data row9 col1\" >0.6241</td>\n",
       "      <td id=\"T_8d71d_row9_col2\" class=\"data row9 col2\" >0.6323</td>\n",
       "      <td id=\"T_8d71d_row9_col3\" class=\"data row9 col3\" >0.7204</td>\n",
       "      <td id=\"T_8d71d_row9_col4\" class=\"data row9 col4\" >0.7049</td>\n",
       "      <td id=\"T_8d71d_row9_col5\" class=\"data row9 col5\" >0.7118</td>\n",
       "      <td id=\"T_8d71d_row9_col6\" class=\"data row9 col6\" >0.1683</td>\n",
       "      <td id=\"T_8d71d_row9_col7\" class=\"data row9 col7\" >0.1685</td>\n",
       "      <td id=\"T_8d71d_row9_col8\" class=\"data row9 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d71d_level0_row10\" class=\"row_heading level0 row10\" >svm</th>\n",
       "      <td id=\"T_8d71d_row10_col0\" class=\"data row10 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_8d71d_row10_col1\" class=\"data row10 col1\" >0.6222</td>\n",
       "      <td id=\"T_8d71d_row10_col2\" class=\"data row10 col2\" >0.6677</td>\n",
       "      <td id=\"T_8d71d_row10_col3\" class=\"data row10 col3\" >0.7558</td>\n",
       "      <td id=\"T_8d71d_row10_col4\" class=\"data row10 col4\" >0.7370</td>\n",
       "      <td id=\"T_8d71d_row10_col5\" class=\"data row10 col5\" >0.6778</td>\n",
       "      <td id=\"T_8d71d_row10_col6\" class=\"data row10 col6\" >0.1325</td>\n",
       "      <td id=\"T_8d71d_row10_col7\" class=\"data row10 col7\" >0.1589</td>\n",
       "      <td id=\"T_8d71d_row10_col8\" class=\"data row10 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d71d_level0_row11\" class=\"row_heading level0 row11\" >gbc</th>\n",
       "      <td id=\"T_8d71d_row11_col0\" class=\"data row11 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_8d71d_row11_col1\" class=\"data row11 col1\" >0.6185</td>\n",
       "      <td id=\"T_8d71d_row11_col2\" class=\"data row11 col2\" >0.6783</td>\n",
       "      <td id=\"T_8d71d_row11_col3\" class=\"data row11 col3\" >0.7810</td>\n",
       "      <td id=\"T_8d71d_row11_col4\" class=\"data row11 col4\" >0.6753</td>\n",
       "      <td id=\"T_8d71d_row11_col5\" class=\"data row11 col5\" >0.7228</td>\n",
       "      <td id=\"T_8d71d_row11_col6\" class=\"data row11 col6\" >0.1160</td>\n",
       "      <td id=\"T_8d71d_row11_col7\" class=\"data row11 col7\" >0.1231</td>\n",
       "      <td id=\"T_8d71d_row11_col8\" class=\"data row11 col8\" >0.0390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d71d_level0_row12\" class=\"row_heading level0 row12\" >knn</th>\n",
       "      <td id=\"T_8d71d_row12_col0\" class=\"data row12 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_8d71d_row12_col1\" class=\"data row12 col1\" >0.6037</td>\n",
       "      <td id=\"T_8d71d_row12_col2\" class=\"data row12 col2\" >0.5683</td>\n",
       "      <td id=\"T_8d71d_row12_col3\" class=\"data row12 col3\" >0.7614</td>\n",
       "      <td id=\"T_8d71d_row12_col4\" class=\"data row12 col4\" >0.6654</td>\n",
       "      <td id=\"T_8d71d_row12_col5\" class=\"data row12 col5\" >0.7077</td>\n",
       "      <td id=\"T_8d71d_row12_col6\" class=\"data row12 col6\" >0.0946</td>\n",
       "      <td id=\"T_8d71d_row12_col7\" class=\"data row12 col7\" >0.1028</td>\n",
       "      <td id=\"T_8d71d_row12_col8\" class=\"data row12 col8\" >0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d71d_level0_row13\" class=\"row_heading level0 row13\" >dt</th>\n",
       "      <td id=\"T_8d71d_row13_col0\" class=\"data row13 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_8d71d_row13_col1\" class=\"data row13 col1\" >0.6000</td>\n",
       "      <td id=\"T_8d71d_row13_col2\" class=\"data row13 col2\" >0.5712</td>\n",
       "      <td id=\"T_8d71d_row13_col3\" class=\"data row13 col3\" >0.6718</td>\n",
       "      <td id=\"T_8d71d_row13_col4\" class=\"data row13 col4\" >0.6957</td>\n",
       "      <td id=\"T_8d71d_row13_col5\" class=\"data row13 col5\" >0.6820</td>\n",
       "      <td id=\"T_8d71d_row13_col6\" class=\"data row13 col6\" >0.1409</td>\n",
       "      <td id=\"T_8d71d_row13_col7\" class=\"data row13 col7\" >0.1412</td>\n",
       "      <td id=\"T_8d71d_row13_col8\" class=\"data row13 col8\" >0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8d71d_level0_row14\" class=\"row_heading level0 row14\" >qda</th>\n",
       "      <td id=\"T_8d71d_row14_col0\" class=\"data row14 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_8d71d_row14_col1\" class=\"data row14 col1\" >0.5889</td>\n",
       "      <td id=\"T_8d71d_row14_col2\" class=\"data row14 col2\" >0.6445</td>\n",
       "      <td id=\"T_8d71d_row14_col3\" class=\"data row14 col3\" >0.6085</td>\n",
       "      <td id=\"T_8d71d_row14_col4\" class=\"data row14 col4\" >0.7157</td>\n",
       "      <td id=\"T_8d71d_row14_col5\" class=\"data row14 col5\" >0.6542</td>\n",
       "      <td id=\"T_8d71d_row14_col6\" class=\"data row14 col6\" >0.1476</td>\n",
       "      <td id=\"T_8d71d_row14_col7\" class=\"data row14 col7\" >0.1502</td>\n",
       "      <td id=\"T_8d71d_row14_col8\" class=\"data row14 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe0a26d3fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_510fe_row9_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_510fe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_510fe_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_510fe_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_510fe_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_510fe_row0_col1\" class=\"data row0 col1\" >5863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_510fe_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_510fe_row1_col1\" class=\"data row1 col1\" >H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_510fe_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_510fe_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_510fe_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_510fe_row3_col1\" class=\"data row3 col1\" >(1070, 43)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_510fe_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_510fe_row4_col1\" class=\"data row4 col1\" >(1070, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_510fe_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_510fe_row5_col1\" class=\"data row5 col1\" >(534, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_510fe_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_510fe_row6_col1\" class=\"data row6 col1\" >(536, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_510fe_row7_col0\" class=\"data row7 col0\" >Ignore features</td>\n",
       "      <td id=\"T_510fe_row7_col1\" class=\"data row7 col1\" >11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_510fe_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_510fe_row8_col1\" class=\"data row8 col1\" >31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_510fe_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_510fe_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_510fe_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_510fe_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_510fe_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_510fe_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_510fe_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_510fe_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_510fe_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_510fe_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_510fe_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_510fe_row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_510fe_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_510fe_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_510fe_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_510fe_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_510fe_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_510fe_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_510fe_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_510fe_row18_col1\" class=\"data row18 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_510fe_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_510fe_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_510fe_row19_col1\" class=\"data row19 col1\" >bf46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe0a1e9ce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_09621 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_09621_row0_col0, #T_09621_row0_col2, #T_09621_row0_col3, #T_09621_row0_col4, #T_09621_row0_col5, #T_09621_row1_col0, #T_09621_row1_col1, #T_09621_row1_col2, #T_09621_row1_col3, #T_09621_row1_col4, #T_09621_row1_col5, #T_09621_row1_col6, #T_09621_row1_col7, #T_09621_row2_col0, #T_09621_row2_col1, #T_09621_row2_col2, #T_09621_row2_col3, #T_09621_row2_col4, #T_09621_row2_col5, #T_09621_row2_col6, #T_09621_row2_col7, #T_09621_row3_col0, #T_09621_row3_col1, #T_09621_row3_col2, #T_09621_row3_col3, #T_09621_row3_col4, #T_09621_row3_col5, #T_09621_row3_col6, #T_09621_row3_col7, #T_09621_row4_col0, #T_09621_row4_col1, #T_09621_row4_col2, #T_09621_row4_col3, #T_09621_row4_col4, #T_09621_row4_col5, #T_09621_row4_col6, #T_09621_row4_col7, #T_09621_row5_col0, #T_09621_row5_col1, #T_09621_row5_col2, #T_09621_row5_col3, #T_09621_row5_col4, #T_09621_row5_col5, #T_09621_row5_col6, #T_09621_row5_col7, #T_09621_row6_col0, #T_09621_row6_col1, #T_09621_row6_col2, #T_09621_row6_col3, #T_09621_row6_col4, #T_09621_row6_col5, #T_09621_row6_col6, #T_09621_row6_col7, #T_09621_row7_col0, #T_09621_row7_col1, #T_09621_row7_col2, #T_09621_row7_col3, #T_09621_row7_col5, #T_09621_row7_col6, #T_09621_row7_col7, #T_09621_row8_col0, #T_09621_row8_col1, #T_09621_row8_col2, #T_09621_row8_col3, #T_09621_row8_col4, #T_09621_row8_col5, #T_09621_row8_col6, #T_09621_row8_col7, #T_09621_row9_col0, #T_09621_row9_col1, #T_09621_row9_col2, #T_09621_row9_col4, #T_09621_row9_col6, #T_09621_row9_col7, #T_09621_row10_col0, #T_09621_row10_col1, #T_09621_row10_col2, #T_09621_row10_col3, #T_09621_row10_col4, #T_09621_row10_col5, #T_09621_row10_col6, #T_09621_row10_col7, #T_09621_row11_col0, #T_09621_row11_col1, #T_09621_row11_col2, #T_09621_row11_col3, #T_09621_row11_col4, #T_09621_row11_col5, #T_09621_row11_col6, #T_09621_row11_col7, #T_09621_row12_col0, #T_09621_row12_col1, #T_09621_row12_col2, #T_09621_row12_col3, #T_09621_row12_col4, #T_09621_row12_col5, #T_09621_row12_col6, #T_09621_row12_col7, #T_09621_row13_col0, #T_09621_row13_col1, #T_09621_row13_col2, #T_09621_row13_col3, #T_09621_row13_col4, #T_09621_row13_col5, #T_09621_row13_col6, #T_09621_row13_col7, #T_09621_row14_col0, #T_09621_row14_col1, #T_09621_row14_col3, #T_09621_row14_col4, #T_09621_row14_col5, #T_09621_row14_col6, #T_09621_row14_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_09621_row0_col1, #T_09621_row0_col6, #T_09621_row0_col7, #T_09621_row7_col4, #T_09621_row9_col3, #T_09621_row9_col5, #T_09621_row14_col2 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_09621_row0_col8, #T_09621_row1_col8, #T_09621_row2_col8, #T_09621_row3_col8, #T_09621_row4_col8, #T_09621_row5_col8, #T_09621_row6_col8, #T_09621_row7_col8, #T_09621_row8_col8, #T_09621_row11_col8, #T_09621_row12_col8, #T_09621_row13_col8, #T_09621_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_09621_row9_col8, #T_09621_row10_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_09621\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_09621_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_09621_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_09621_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_09621_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_09621_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_09621_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_09621_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_09621_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_09621_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_09621_level0_row0\" class=\"row_heading level0 row0\" >lr</th>\n",
       "      <td id=\"T_09621_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_09621_row0_col1\" class=\"data row0 col1\" >0.6836</td>\n",
       "      <td id=\"T_09621_row0_col2\" class=\"data row0 col2\" >0.6988</td>\n",
       "      <td id=\"T_09621_row0_col3\" class=\"data row0 col3\" >0.8213</td>\n",
       "      <td id=\"T_09621_row0_col4\" class=\"data row0 col4\" >0.7218</td>\n",
       "      <td id=\"T_09621_row0_col5\" class=\"data row0 col5\" >0.7673</td>\n",
       "      <td id=\"T_09621_row0_col6\" class=\"data row0 col6\" >0.2767</td>\n",
       "      <td id=\"T_09621_row0_col7\" class=\"data row0 col7\" >0.2875</td>\n",
       "      <td id=\"T_09621_row0_col8\" class=\"data row0 col8\" >0.0110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09621_level0_row1\" class=\"row_heading level0 row1\" >ridge</th>\n",
       "      <td id=\"T_09621_row1_col0\" class=\"data row1 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_09621_row1_col1\" class=\"data row1 col1\" >0.6817</td>\n",
       "      <td id=\"T_09621_row1_col2\" class=\"data row1 col2\" >0.7018</td>\n",
       "      <td id=\"T_09621_row1_col3\" class=\"data row1 col3\" >0.8272</td>\n",
       "      <td id=\"T_09621_row1_col4\" class=\"data row1 col4\" >0.7179</td>\n",
       "      <td id=\"T_09621_row1_col5\" class=\"data row1 col5\" >0.7678</td>\n",
       "      <td id=\"T_09621_row1_col6\" class=\"data row1 col6\" >0.2673</td>\n",
       "      <td id=\"T_09621_row1_col7\" class=\"data row1 col7\" >0.2786</td>\n",
       "      <td id=\"T_09621_row1_col8\" class=\"data row1 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09621_level0_row2\" class=\"row_heading level0 row2\" >lda</th>\n",
       "      <td id=\"T_09621_row2_col0\" class=\"data row2 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_09621_row2_col1\" class=\"data row2 col1\" >0.6798</td>\n",
       "      <td id=\"T_09621_row2_col2\" class=\"data row2 col2\" >0.7011</td>\n",
       "      <td id=\"T_09621_row2_col3\" class=\"data row2 col3\" >0.8214</td>\n",
       "      <td id=\"T_09621_row2_col4\" class=\"data row2 col4\" >0.7182</td>\n",
       "      <td id=\"T_09621_row2_col5\" class=\"data row2 col5\" >0.7652</td>\n",
       "      <td id=\"T_09621_row2_col6\" class=\"data row2 col6\" >0.2661</td>\n",
       "      <td id=\"T_09621_row2_col7\" class=\"data row2 col7\" >0.2772</td>\n",
       "      <td id=\"T_09621_row2_col8\" class=\"data row2 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09621_level0_row3\" class=\"row_heading level0 row3\" >gbc</th>\n",
       "      <td id=\"T_09621_row3_col0\" class=\"data row3 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_09621_row3_col1\" class=\"data row3 col1\" >0.6782</td>\n",
       "      <td id=\"T_09621_row3_col2\" class=\"data row3 col2\" >0.6466</td>\n",
       "      <td id=\"T_09621_row3_col3\" class=\"data row3 col3\" >0.8332</td>\n",
       "      <td id=\"T_09621_row3_col4\" class=\"data row3 col4\" >0.7125</td>\n",
       "      <td id=\"T_09621_row3_col5\" class=\"data row3 col5\" >0.7673</td>\n",
       "      <td id=\"T_09621_row3_col6\" class=\"data row3 col6\" >0.2535</td>\n",
       "      <td id=\"T_09621_row3_col7\" class=\"data row3 col7\" >0.2644</td>\n",
       "      <td id=\"T_09621_row3_col8\" class=\"data row3 col8\" >0.0380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09621_level0_row4\" class=\"row_heading level0 row4\" >rf</th>\n",
       "      <td id=\"T_09621_row4_col0\" class=\"data row4 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_09621_row4_col1\" class=\"data row4 col1\" >0.6647</td>\n",
       "      <td id=\"T_09621_row4_col2\" class=\"data row4 col2\" >0.6512</td>\n",
       "      <td id=\"T_09621_row4_col3\" class=\"data row4 col3\" >0.8183</td>\n",
       "      <td id=\"T_09621_row4_col4\" class=\"data row4 col4\" >0.7068</td>\n",
       "      <td id=\"T_09621_row4_col5\" class=\"data row4 col5\" >0.7572</td>\n",
       "      <td id=\"T_09621_row4_col6\" class=\"data row4 col6\" >0.2224</td>\n",
       "      <td id=\"T_09621_row4_col7\" class=\"data row4 col7\" >0.2291</td>\n",
       "      <td id=\"T_09621_row4_col8\" class=\"data row4 col8\" >0.0240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09621_level0_row5\" class=\"row_heading level0 row5\" >lightgbm</th>\n",
       "      <td id=\"T_09621_row5_col0\" class=\"data row5 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_09621_row5_col1\" class=\"data row5 col1\" >0.6575</td>\n",
       "      <td id=\"T_09621_row5_col2\" class=\"data row5 col2\" >0.6398</td>\n",
       "      <td id=\"T_09621_row5_col3\" class=\"data row5 col3\" >0.8006</td>\n",
       "      <td id=\"T_09621_row5_col4\" class=\"data row5 col4\" >0.7043</td>\n",
       "      <td id=\"T_09621_row5_col5\" class=\"data row5 col5\" >0.7484</td>\n",
       "      <td id=\"T_09621_row5_col6\" class=\"data row5 col6\" >0.2158</td>\n",
       "      <td id=\"T_09621_row5_col7\" class=\"data row5 col7\" >0.2213</td>\n",
       "      <td id=\"T_09621_row5_col8\" class=\"data row5 col8\" >0.0830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09621_level0_row6\" class=\"row_heading level0 row6\" >ada</th>\n",
       "      <td id=\"T_09621_row6_col0\" class=\"data row6 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_09621_row6_col1\" class=\"data row6 col1\" >0.6463</td>\n",
       "      <td id=\"T_09621_row6_col2\" class=\"data row6 col2\" >0.6362</td>\n",
       "      <td id=\"T_09621_row6_col3\" class=\"data row6 col3\" >0.7599</td>\n",
       "      <td id=\"T_09621_row6_col4\" class=\"data row6 col4\" >0.7079</td>\n",
       "      <td id=\"T_09621_row6_col5\" class=\"data row6 col5\" >0.7319</td>\n",
       "      <td id=\"T_09621_row6_col6\" class=\"data row6 col6\" >0.2116</td>\n",
       "      <td id=\"T_09621_row6_col7\" class=\"data row6 col7\" >0.2147</td>\n",
       "      <td id=\"T_09621_row6_col8\" class=\"data row6 col8\" >0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09621_level0_row7\" class=\"row_heading level0 row7\" >nb</th>\n",
       "      <td id=\"T_09621_row7_col0\" class=\"data row7 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_09621_row7_col1\" class=\"data row7 col1\" >0.6444</td>\n",
       "      <td id=\"T_09621_row7_col2\" class=\"data row7 col2\" >0.6709</td>\n",
       "      <td id=\"T_09621_row7_col3\" class=\"data row7 col3\" >0.6866</td>\n",
       "      <td id=\"T_09621_row7_col4\" class=\"data row7 col4\" >0.7395</td>\n",
       "      <td id=\"T_09621_row7_col5\" class=\"data row7 col5\" >0.7089</td>\n",
       "      <td id=\"T_09621_row7_col6\" class=\"data row7 col6\" >0.2504</td>\n",
       "      <td id=\"T_09621_row7_col7\" class=\"data row7 col7\" >0.2548</td>\n",
       "      <td id=\"T_09621_row7_col8\" class=\"data row7 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09621_level0_row8\" class=\"row_heading level0 row8\" >xgboost</th>\n",
       "      <td id=\"T_09621_row8_col0\" class=\"data row8 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_09621_row8_col1\" class=\"data row8 col1\" >0.6406</td>\n",
       "      <td id=\"T_09621_row8_col2\" class=\"data row8 col2\" >0.6397</td>\n",
       "      <td id=\"T_09621_row8_col3\" class=\"data row8 col3\" >0.7800</td>\n",
       "      <td id=\"T_09621_row8_col4\" class=\"data row8 col4\" >0.6954</td>\n",
       "      <td id=\"T_09621_row8_col5\" class=\"data row8 col5\" >0.7344</td>\n",
       "      <td id=\"T_09621_row8_col6\" class=\"data row8 col6\" >0.1813</td>\n",
       "      <td id=\"T_09621_row8_col7\" class=\"data row8 col7\" >0.1849</td>\n",
       "      <td id=\"T_09621_row8_col8\" class=\"data row8 col8\" >0.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09621_level0_row9\" class=\"row_heading level0 row9\" >dummy</th>\n",
       "      <td id=\"T_09621_row9_col0\" class=\"data row9 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_09621_row9_col1\" class=\"data row9 col1\" >0.6386</td>\n",
       "      <td id=\"T_09621_row9_col2\" class=\"data row9 col2\" >0.5000</td>\n",
       "      <td id=\"T_09621_row9_col3\" class=\"data row9 col3\" >1.0000</td>\n",
       "      <td id=\"T_09621_row9_col4\" class=\"data row9 col4\" >0.6386</td>\n",
       "      <td id=\"T_09621_row9_col5\" class=\"data row9 col5\" >0.7794</td>\n",
       "      <td id=\"T_09621_row9_col6\" class=\"data row9 col6\" >0.0000</td>\n",
       "      <td id=\"T_09621_row9_col7\" class=\"data row9 col7\" >0.0000</td>\n",
       "      <td id=\"T_09621_row9_col8\" class=\"data row9 col8\" >0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09621_level0_row10\" class=\"row_heading level0 row10\" >qda</th>\n",
       "      <td id=\"T_09621_row10_col0\" class=\"data row10 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_09621_row10_col1\" class=\"data row10 col1\" >0.6349</td>\n",
       "      <td id=\"T_09621_row10_col2\" class=\"data row10 col2\" >0.6429</td>\n",
       "      <td id=\"T_09621_row10_col3\" class=\"data row10 col3\" >0.6922</td>\n",
       "      <td id=\"T_09621_row10_col4\" class=\"data row10 col4\" >0.7260</td>\n",
       "      <td id=\"T_09621_row10_col5\" class=\"data row10 col5\" >0.7065</td>\n",
       "      <td id=\"T_09621_row10_col6\" class=\"data row10 col6\" >0.2209</td>\n",
       "      <td id=\"T_09621_row10_col7\" class=\"data row10 col7\" >0.2235</td>\n",
       "      <td id=\"T_09621_row10_col8\" class=\"data row10 col8\" >0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09621_level0_row11\" class=\"row_heading level0 row11\" >et</th>\n",
       "      <td id=\"T_09621_row11_col0\" class=\"data row11 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_09621_row11_col1\" class=\"data row11 col1\" >0.6330</td>\n",
       "      <td id=\"T_09621_row11_col2\" class=\"data row11 col2\" >0.6320</td>\n",
       "      <td id=\"T_09621_row11_col3\" class=\"data row11 col3\" >0.8064</td>\n",
       "      <td id=\"T_09621_row11_col4\" class=\"data row11 col4\" >0.6794</td>\n",
       "      <td id=\"T_09621_row11_col5\" class=\"data row11 col5\" >0.7365</td>\n",
       "      <td id=\"T_09621_row11_col6\" class=\"data row11 col6\" >0.1421</td>\n",
       "      <td id=\"T_09621_row11_col7\" class=\"data row11 col7\" >0.1504</td>\n",
       "      <td id=\"T_09621_row11_col8\" class=\"data row11 col8\" >0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09621_level0_row12\" class=\"row_heading level0 row12\" >knn</th>\n",
       "      <td id=\"T_09621_row12_col0\" class=\"data row12 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_09621_row12_col1\" class=\"data row12 col1\" >0.6235</td>\n",
       "      <td id=\"T_09621_row12_col2\" class=\"data row12 col2\" >0.6114</td>\n",
       "      <td id=\"T_09621_row12_col3\" class=\"data row12 col3\" >0.7861</td>\n",
       "      <td id=\"T_09621_row12_col4\" class=\"data row12 col4\" >0.6762</td>\n",
       "      <td id=\"T_09621_row12_col5\" class=\"data row12 col5\" >0.7263</td>\n",
       "      <td id=\"T_09621_row12_col6\" class=\"data row12 col6\" >0.1309</td>\n",
       "      <td id=\"T_09621_row12_col7\" class=\"data row12 col7\" >0.1367</td>\n",
       "      <td id=\"T_09621_row12_col8\" class=\"data row12 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09621_level0_row13\" class=\"row_heading level0 row13\" >dt</th>\n",
       "      <td id=\"T_09621_row13_col0\" class=\"data row13 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_09621_row13_col1\" class=\"data row13 col1\" >0.5843</td>\n",
       "      <td id=\"T_09621_row13_col2\" class=\"data row13 col2\" >0.5599</td>\n",
       "      <td id=\"T_09621_row13_col3\" class=\"data row13 col3\" >0.6482</td>\n",
       "      <td id=\"T_09621_row13_col4\" class=\"data row13 col4\" >0.6841</td>\n",
       "      <td id=\"T_09621_row13_col5\" class=\"data row13 col5\" >0.6637</td>\n",
       "      <td id=\"T_09621_row13_col6\" class=\"data row13 col6\" >0.1179</td>\n",
       "      <td id=\"T_09621_row13_col7\" class=\"data row13 col7\" >0.1184</td>\n",
       "      <td id=\"T_09621_row13_col8\" class=\"data row13 col8\" >0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09621_level0_row14\" class=\"row_heading level0 row14\" >svm</th>\n",
       "      <td id=\"T_09621_row14_col0\" class=\"data row14 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_09621_row14_col1\" class=\"data row14 col1\" >0.5655</td>\n",
       "      <td id=\"T_09621_row14_col2\" class=\"data row14 col2\" >0.7044</td>\n",
       "      <td id=\"T_09621_row14_col3\" class=\"data row14 col3\" >0.5262</td>\n",
       "      <td id=\"T_09621_row14_col4\" class=\"data row14 col4\" >0.7024</td>\n",
       "      <td id=\"T_09621_row14_col5\" class=\"data row14 col5\" >0.5474</td>\n",
       "      <td id=\"T_09621_row14_col6\" class=\"data row14 col6\" >0.1474</td>\n",
       "      <td id=\"T_09621_row14_col7\" class=\"data row14 col7\" >0.1890</td>\n",
       "      <td id=\"T_09621_row14_col8\" class=\"data row14 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe0a24ae810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_cls = []\n",
    "\n",
    "seasons = df[\"Season\"].unique()\n",
    "for i in range(len(seasons) - 1):\n",
    "    df_train = df_ml3[df_ml3[\"Season\"] == seasons[i]]\n",
    "    df_test = df_ml3[df_ml3[\"Season\"] == seasons[i + 1]]\n",
    "\n",
    "    py_cls = ClassificationExperiment()\n",
    "\n",
    "    setup_params_cls = {\n",
    "        \"data\": df_train,\n",
    "        \"test_data\": df_test,\n",
    "        \"target\": \"H\",\n",
    "        \"ignore_features\": [\"Season\", \"Date\", \"HID\", \"AID\", \"N\", \"POFF\", \"Open\", \"OddsH\", \"OddsA\", \"A\", \"SortedTID\"],\n",
    "    }\n",
    "\n",
    "    py_cls.setup(**setup_params_cls)\n",
    "    best_model_cls.append((i, py_cls.compare_models(turbo=True, sort=\"Accuracy\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/22 AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=2341)\n",
      "22/23 RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, positive=False, random_state=6851, solver='auto',\n",
      "                tol=0.0001)\n",
      "23/24 LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=6615, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "for i, model in best_model_cls:\n",
    "    print(f\"{seasons[i]:>2}/{seasons[i + 1]:>2}\", model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple sklearn\n",
    "\n",
    "### Season train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/22, Acc Tr: 67.53%, B. Acc Tr: 64.19%, Acc Ts: 69.51%, B. Acc Ts: 64.88%, Return Tr: 49.202, Return Ts: 22.327\n",
      "22/23, Acc Tr: 71.48%, B. Acc Tr: 68.58%, Acc Ts: 70.95%, B. Acc Ts: 68.01%, Return Tr: 95.788, Return Ts: 53.339\n",
      "23/24, Acc Tr: 71.94%, B. Acc Tr: 68.85%, Acc Ts: 69.51%, B. Acc Ts: 69.11%, Return Tr: 66.906, Return Ts: 97.508\n"
     ]
    }
   ],
   "source": [
    "seasons = df[\"Season\"].unique()\n",
    "for i in range(len(seasons) - 1):\n",
    "    df_train = df_ml1[df_ml1[\"Season\"] == seasons[i]]\n",
    "    df_test = df_ml1[df_ml1[\"Season\"] == seasons[i + 1]]\n",
    "\n",
    "    y_train, X_train = patsy.dmatrices(formula, df_train, return_type=\"matrix\")\n",
    "    y_test, X_test = patsy.dmatrices(formula, df_test, return_type=\"matrix\")\n",
    "\n",
    "    y_train = y_train.flatten()\n",
    "\n",
    "    # model = LogisticRegression(max_iter=10_000)\n",
    "    # model = GradientBoostingClassifier()\n",
    "    model = RidgeClassifier()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    p_train = model.predict(X_train)\n",
    "    p_test = model.predict(X_test)\n",
    "\n",
    "    bac_train = balanced_accuracy_score(y_train, p_train)\n",
    "    ac_train = accuracy_score(y_train, p_train)\n",
    "    bac_test = balanced_accuracy_score(y_test, p_test)\n",
    "    ac_test = accuracy_score(y_test, p_test)\n",
    "\n",
    "    r_train, _ = calc_return(df_train, p_train)\n",
    "    r_test, _ = calc_return(df_test, p_test)\n",
    "\n",
    "\n",
    "    print(f\"{seasons[i]:>2}/{seasons[i + 1]:>2}, Acc Tr: {ac_train :.2%}, B. Acc Tr: {bac_train :.2%}, Acc Ts: {ac_test :.2%}, B. Acc Ts: {bac_test :.2%}, Return Tr: {r_train:.3f}, Return Ts: {r_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(model, X):\n",
    "    d = model.decision_function(X)\n",
    "    return np.exp(d) / (1 + np.exp(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc Tr: 70.06%, B. Acc Tr: 67.11%, Acc Ts: 69.54%, B. Acc Ts: 66.66%, Return Tr: 127.358, Return Ts: 104.102\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df_ml1, test_size=0.5)\n",
    "\n",
    "y_train, X_train = patsy.dmatrices(formula, df_train, return_type=\"matrix\")\n",
    "y_test, X_test = patsy.dmatrices(formula, df_test, return_type=\"matrix\")\n",
    "\n",
    "y_train = y_train.flatten()\n",
    "\n",
    "# model = LogisticRegression(max_iter=10_000)\n",
    "# model = GradientBoostingClassifier()\n",
    "model = RidgeClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "p_train = model.predict(X_train)\n",
    "p_test = model.predict(X_test)\n",
    "pb_train = predict_proba(model, X_train)\n",
    "pb_test = predict_proba(model, X_test)\n",
    "\n",
    "bac_train = balanced_accuracy_score(y_train, p_train)\n",
    "ac_train = accuracy_score(y_train, p_train)\n",
    "bac_test = balanced_accuracy_score(y_test, p_test)\n",
    "ac_test = accuracy_score(y_test, p_test)\n",
    "\n",
    "r_train, rs_train = calc_return(df_train, p_train)\n",
    "r_test, rs_test = calc_return(df_test, p_test)\n",
    "\n",
    "\n",
    "print(f\"Acc Tr: {ac_train :.2%}, B. Acc Tr: {bac_train :.2%}, Acc Ts: {ac_test :.2%}, B. Acc Ts: {bac_test :.2%}, Return Tr: {r_train:.3f}, Return Ts: {r_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootsraping results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(p, df, n=1000):\n",
    "\n",
    "    def _calc_return(df):\n",
    "        r = 0\n",
    "        rs= []\n",
    "        for _, row in df.iterrows():\n",
    "            r -= 1\n",
    "            if row[\"p\"] and row[\"H\"]:\n",
    "                r += row[\"OddsH\"]\n",
    "            \n",
    "            if not row[\"p\"] and row[\"A\"]:\n",
    "                r += row[\"OddsA\"]\n",
    "\n",
    "            rs.append(r)\n",
    "\n",
    "        return rs\n",
    "\n",
    "    df_p = df[[\"H\", \"A\", \"OddsH\", \"OddsA\"]].copy()\n",
    "    df_p[\"p\"] = p\n",
    "\n",
    "    rs = []\n",
    "    for _ in range(n):\n",
    "        df_s = df_p.sample(len(df_p), replace=True)\n",
    "        rs.append(_calc_return(df_s))\n",
    "    \n",
    "    return rs\n",
    "\n",
    "def calc_envelope(rs):\n",
    "    rs = np.array(rs)\n",
    "    return rs.min(axis=0), rs.max(axis=0)\n",
    "\n",
    "\n",
    "def bootstrap_proba(p, df, offset=0.1, n=1000):\n",
    "\n",
    "    def _calc_return(df, offset):\n",
    "        r = 0\n",
    "        rs= []\n",
    "        for _, row in df.iterrows():\n",
    "            if (1 - row[\"p\"] + offset) < (1 / row[\"OddsA\"]):\n",
    "                r -= 1\n",
    "                if row[\"H\"]:\n",
    "                    r += row[\"OddsH\"]\n",
    "    \n",
    "            if row[\"p\"] + offset < (1 / row[\"OddsH\"]):\n",
    "                r -= 1\n",
    "                if row[\"A\"]:\n",
    "                    r += row[\"OddsA\"]\n",
    "\n",
    "            rs.append(r)\n",
    "\n",
    "        return rs\n",
    "\n",
    "    df_p = df[[\"H\", \"A\", \"OddsH\", \"OddsA\"]].copy()\n",
    "    df_p[\"p\"] = p\n",
    "\n",
    "    rs = []\n",
    "    for _ in range(n):\n",
    "        df_s = df_p.sample(len(df_p), replace=True)\n",
    "        rs.append(_calc_return(df_s, offset))\n",
    "    \n",
    "    return rs\n",
    "\n",
    "def calc_envelope(rs):\n",
    "    rs = np.array(rs)\n",
    "    return rs.min(axis=0), rs.max(axis=0), rs.mean(axis=0), np.median(rs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_n = 100\n",
    "bs_offset = 0.3\n",
    "rs = bootstrap_proba(pb_test, df_test, offset=bs_offset, n=bs_n)\n",
    "rs_min, rs_max, rs_mean, rs_median = calc_envelope(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_n = 1000\n",
    "rs = bootstrap(p_test, df_test, n=bs_n)\n",
    "rs_min, rs_max, rs_mean, rs_median = calc_envelope(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name3_proba = f\"results_roll{rolling_n}_proba_offset{bs_offset}_test_bs{bs_n}.pdf\"\n",
    "name3 = f\"results_roll{rolling_n}_test_bs{bs_n}.pdf\"\n",
    "\n",
    "name1_proba = f\"results_allSeasonData_proba_offset{bs_offset}_test_bs{bs_n}.pdf\"\n",
    "name1 = f\"results_allSeasonData_test_bs{bs_n}.pdf\"\n",
    "\n",
    "plt.title(\"Potential Return\")\n",
    "plt.xlabel(\"Games\")\n",
    "plt.ylabel(\"$\")\n",
    "plt.plot(rs_min, color=\"red\", label=\"min\", lw=3)\n",
    "plt.plot(rs_max, color=\"green\", label=\"max\", lw=3)\n",
    "plt.plot(rs_mean, color=\"blue\", label=\"mean\", lw=3)\n",
    "plt.plot(rs_median, color=\"orange\", label=\"median\", lw=3)\n",
    "plt.fill_between(range(len(rs_min)), rs_min, rs_max, color=\"gray\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(\"..\", \"plots\", name1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qqh-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
